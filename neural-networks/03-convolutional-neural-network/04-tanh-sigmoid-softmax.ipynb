{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 更多激活函数\n",
    "\n",
    "在上一个章节，我们通过引入丢弃层，添加“白噪音”，来解决网络模型”过度关注细节“造成的过拟合问题。\n",
    "\n",
    "现在，让我们讨论一下照片”曝光过度\"带来的极端数值可能带来的**梯度爆炸**（Exploding Gradient）、或者**梯度消失**（Vanishing Gradient）问题。\n",
    "\n",
    "还记得我们在 MNIST 数据集中，通过归一化将所有像素数据从(0, 255)的整数转换成(0, 1)的小数吗？主要原因就是过大的特征值在经过层层累乘放大后，会导致计算结果“爆表”或者反馈信号彻底消失。通过归一化可以有效地解决这个问题。\n",
    "\n",
    "但是数值过大的问题不止会发生在输入层，各层产生的中间值也可能有这个问题。这时候我们可以通过引入更多类型的激活函数层来应对不同的数据问题。\n",
    "\n",
    "我们已经使用过 ReLU 激活函数，通过负数归零的办法，用来消除噪音、无效数据。其他最常用的激活函数还有：\n",
    "\n",
    "* **Tanh 激活函数**：它可以将任何数值映射到(-1, 1)的范围内，同时保持数值之间的相对关系。可以用来消除“曝光过度”造成的极端数值，使数据分布在零点附近。和 ReLU 激活函数一样，常用于中间隐藏层。\n",
    "* **Sigmoid 激活函数**：它可以把任何数值平滑地压缩到(0, 1)的范围之间。因此可以解释为某个事件发生的概率，常用于二元分类问题的输出层，来规范预测结果。\n",
    "* **Softmax 激活函数**：它用于一组数值的情况，将它们转换为相互之间的相对比例，并维持总和为1。因此常用于多元分类问题的输出层，数值最大的那个选项就是预测结果。"
   ],
   "id": "42f6bfd377c98ed8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:09.741385951Z",
     "start_time": "2026-01-19T04:05:09.512959477Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from abc import abstractmethod, ABC\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(99)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 基础架构",
   "id": "b9ec67c80687636e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 张量",
   "id": "cb3f056c1a32d1b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:09.816776722Z",
     "start_time": "2026-01-19T04:05:09.760209082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.grad = np.zeros_like(self.data)\n",
    "        self.gradient_fn = lambda: None\n",
    "        self.parents = set()\n",
    "\n",
    "    def backward(self):\n",
    "        if self.gradient_fn:\n",
    "            self.gradient_fn()\n",
    "\n",
    "        for p in self.parents:\n",
    "            p.backward()\n",
    "\n",
    "    def size(self):\n",
    "        return np.prod(self.data.shape[1:])\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Tensor({self.data})'"
   ],
   "id": "9e1ca6c8a30aa3cf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础数据集",
   "id": "e6cd4f62de20e028"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:09.871033455Z",
     "start_time": "2026-01-19T04:05:09.823855980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dataset(ABC):\n",
    "\n",
    "    def __init__(self, batch_size=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.load()\n",
    "        self.train()\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        self.features = self.train_features\n",
    "        self.labels = self.train_labels\n",
    "\n",
    "    def eval(self):\n",
    "        self.features = self.test_features\n",
    "        self.labels = self.test_labels\n",
    "\n",
    "    def shape(self):\n",
    "        return Tensor(self.features).size(), Tensor(self.labels).size()\n",
    "\n",
    "    def items(self):\n",
    "        return Tensor(self.features), Tensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "\n",
    "        feature = Tensor(self.features[start: end])\n",
    "        label = Tensor(self.labels[start: end])\n",
    "        return feature, label"
   ],
   "id": "6cfa087678386d9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础层",
   "id": "d8cb0e7e6307c067"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:09.935701744Z",
     "start_time": "2026-01-19T04:05:09.878673154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(ABC):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.training = True\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: Tensor):\n",
    "        pass\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "    def __str__(self):\n",
    "        return ''"
   ],
   "id": "68a841612245abd8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础损失函数",
   "id": "8c6f650bfb89414d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:09.975053002Z",
     "start_time": "2026-01-19T04:05:09.940026728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss(ABC):\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        return self.loss(p, y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        pass"
   ],
   "id": "984e2d331c53896e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础优化器",
   "id": "3fd8b447e5ac7a5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:10.012193122Z",
     "start_time": "2026-01-19T04:05:09.982812403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Optimizer(ABC):\n",
    "\n",
    "    def __init__(self, parameters, lr):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "\n",
    "    def reset(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad = np.zeros_like(p.data)\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self):\n",
    "        pass"
   ],
   "id": "aad841b6c5d0f661",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础模型",
   "id": "c5bc153ecea1a0c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:10.049522126Z",
     "start_time": "2026-01-19T04:05:10.019318022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(ABC):\n",
    "\n",
    "    def __init__(self, layer, loss_fn, optimizer):\n",
    "        self.layer = layer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, dataset, epochs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def test(self, dataset):\n",
    "        pass"
   ],
   "id": "32cddbb1dcf1bc94",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据",
   "id": "22f060a706fe89f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MNIST 数据集",
   "id": "86c7a1883559b39d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:10.107852147Z",
     "start_time": "2026-01-19T04:05:10.055979630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MNISTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename, batch_size=1):\n",
    "        self.filename = filename\n",
    "        super().__init__(batch_size)\n",
    "\n",
    "    def load(self):\n",
    "        with (np.load(self.filename, allow_pickle=True) as f):\n",
    "            self.train_features, self.train_labels = self.normalize(f['x_train'], f['y_train'])\n",
    "            self.test_features, self.test_labels = self.normalize(f['x_test'], f['y_test'])\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(x, y):\n",
    "        inputs = x / 255\n",
    "        inputs = np.expand_dims(inputs, axis=1)\n",
    "        targets = np.zeros((len(y), 10))\n",
    "        targets[range(len(y)), y] = 1\n",
    "        return inputs, targets\n",
    "\n",
    "    def estimate(self, predictions):\n",
    "        count = (predictions.data.argmax(axis=1) == self.labels.argmax(axis=1)).sum()\n",
    "        total = len(self.labels)\n",
    "        return count / total"
   ],
   "id": "8348d98e13e2010",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型",
   "id": "40e2172e2ad6cc14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 线性层",
   "id": "9fe2549ec77e7f95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:10.263244205Z",
     "start_time": "2026-01-19T04:05:10.126669835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.weight = Tensor(np.random.rand(out_size, in_size) / in_size)\n",
    "        self.bias = Tensor(np.random.rand(out_size))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(x.data @ self.weight.data.T + self.bias.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.weight.grad += p.grad.T @ x.data\n",
    "            self.bias.grad += np.sum(p.grad, axis=0)\n",
    "            x.grad += p.grad @ self.weight.data\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight, self.bias]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Linear[weight{self.weight.data.shape}; bias{self.bias.data.shape}]'"
   ],
   "id": "79336d442854a26c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 顺序层",
   "id": "48cd299bc1447612"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:10.600572835Z",
     "start_time": "2026-01-19T04:05:10.358375832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sequential(Layer):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "\n",
    "    def train(self):\n",
    "        for l in self.layers:\n",
    "            l.train()\n",
    "\n",
    "    def eval(self):\n",
    "        for l in self.layers:\n",
    "            l.eval()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join(str(l) for l in self.layers if str(l))"
   ],
   "id": "1e59636243258db0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 展平层",
   "id": "669b057c9d99f164"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:10.670982750Z",
     "start_time": "2026-01-19T04:05:10.629214483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Flatten(Layer):\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(np.array(x.data.reshape(x.data.shape[0], -1)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad += p.grad.reshape(x.data.shape)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Flatten[]'"
   ],
   "id": "5c37188cedf2d2d3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 丢弃层",
   "id": "3592db81ecf08955"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:10.743573500Z",
     "start_time": "2026-01-19T04:05:10.682258763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dropout(Layer):\n",
    "\n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        if not self.training:\n",
    "            return x\n",
    "\n",
    "        mask = np.random.random(x.data.shape) > self.dropout_rate\n",
    "        p = Tensor(x.data * mask)\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad += p.grad * mask\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Dropout[rate={self.dropout_rate}]'"
   ],
   "id": "d17ec70f90f03f7b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ReLU 激活函数\n",
    "\n",
    "前向传播：负数清零。\n",
    "$$\n",
    "y = \\text{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "梯度计算：正数保留梯度。ReLU函数的导数为：\n",
    "$$\n",
    "\\frac{dy}{dx} = \\begin{cases} 1 & \\text{if } x > 0 \\\\ 0 & \\text{if } x \\leq 0 \\end{cases}\n",
    "$$"
   ],
   "id": "bbbefbd8eb4bb157"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:10.782146309Z",
     "start_time": "2026-01-19T04:05:10.746662467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReLU(Layer):\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(np.maximum(0, x.data))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad += p.grad * (p.data > 0)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'ReLU[]'"
   ],
   "id": "9f8cf5cdb826bf5b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们看一下 ReLU 激活函数的效果：",
   "id": "47b5254dd9da84ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:11.710227100Z",
     "start_time": "2026-01-19T04:05:10.790271920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "relu = ReLU()\n",
    "x_range = np.arange(-10, 10, 0.1)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(x_range, [relu(Tensor(x)).data for x in x_range], linewidth=2)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('ReLU', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9947838f5df56753",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tanh 激活函数\n",
    "\n",
    "前向传播：双曲正切，将输入值映射到(-1, 1)范围内。输出值零中心化（均值为0）。我们直接调用NumPy提供的tanh()函数来计算。\n",
    "$$\n",
    "y = \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
    "$$\n",
    "\n",
    "梯度计算：Tanh函数的导数可以用其自身来表达。这意味着我们不需要重新计算复杂的指数函数。Tanh函数的导数为：\n",
    "$$\n",
    "\\frac{dy}{dx} = 1 - \\tanh^2(x) = 1 - y^2\n",
    "$$\n",
    "\n",
    "当输入值很大、或者很小的时候，导数会趋近于0。这就是我们常说的**梯度饱和**（Gradient Saturation）现象。在深层网络中，这会导致传回来的信号越来越弱，最终引发梯度消失。"
   ],
   "id": "bfa615d065014f60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Tanh(Layer):\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(np.tanh(x.data))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad += p.grad * (1 - p.data ** 2)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Tanh[]'"
   ],
   "id": "37e298b731c3f030"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们看一下 Tanh 激活函数的效果：",
   "id": "dcf66fc99ca335fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tanh = Tanh()\n",
    "x_range = np.arange(-10, 10, 0.1)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(x_range, [tanh(Tensor(x)).data for x in x_range], linewidth=2)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Tanh', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "495681dcf7eafdfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sigmoid 激活函数\n",
    "\n",
    "前向传播：逻辑回归的概率，将任意实数映射到(0, 1)区间内。常用于二元分类问题的输出层。\n",
    "$$\n",
    "y = \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "梯度计算：Sigmoid函数的导数也可以用其自身来表达。Sigmoid函数的导数为：\n",
    "$$\n",
    "\\frac{dy}{dx} = \\sigma(x) \\cdot (1 - \\sigma(x)) = y(1 - y)\n",
    "$$\n",
    "\n",
    "Sigmoid函数同样存在梯度饱和的问题。在深层网络中，可能梯度消失。而且，Sigmoid函数还存在梯度衰减的问题。"
   ],
   "id": "6efcfcc3f69029fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Sigmoid(Layer):\n",
    "\n",
    "    def __init__(self, clip_range=(-100, 100)):\n",
    "        super().__init__()\n",
    "        self.clip_range = clip_range\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        z = np.clip(x.data, self.clip_range[0], self.clip_range[1])\n",
    "        p = Tensor(1 / (1 + np.exp(-z)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad += p.grad * p.data * (1 - p.data)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Sigmoid[]'"
   ],
   "id": "c735a557a30c1441"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们看一下 Sigmoid 激活函数的效果：",
   "id": "22c4177c667a20f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sigmiod = Sigmoid()\n",
    "x_range = np.arange(-10, 10, 0.1)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(x_range, [sigmiod(Tensor(x)).data for x in x_range], linewidth=2)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Sigmoid', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a3a0f1d5aaa5692e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Softmax 激活函数\n",
    "\n",
    "前向传播：将任意实数向量映射为一个概率分布，使得每个分量位于(0,1)区间内，且所有分量之和为1。常用于多分元分类问题的输出层。\n",
    "$$\n",
    "y_i = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}\n",
    "$$\n",
    "\n",
    "梯度计算：Softmax是一个向量函数，其梯度为Jacobian矩阵。Softmax函数的导数为：\n",
    "$$\n",
    "\\frac{dy_i}{dx_i} = g_i - \\sum_{j=1}^{n} y_i g_i\n",
    "$$"
   ],
   "id": "ea666d0ddd41e0a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Softmax(Layer):\n",
    "\n",
    "    def __init__(self, axis=-1):\n",
    "        super().__init__()\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        exp = np.exp(x.data - np.max(x.data, axis=self.axis, keepdims=True))\n",
    "        p = Tensor(exp / np.sum(exp, axis=self.axis, keepdims=True))\n",
    "\n",
    "        def gradient_fn():\n",
    "            grad = np.sum(p.data * p.grad, axis=self.axis, keepdims=True)\n",
    "            x.grad += p.data * (p.grad - grad)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Softmax[]'"
   ],
   "id": "25b3c3a4257d6251"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们看一下 Softmax 激活函数的效果：",
   "id": "5a4b6de6525bf3e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "softmax = Softmax()\n",
    "x_range = np.arange(-10, 10, 0.1)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(x_range, [softmax(Tensor([x,0.1,0.9])).data for x in x_range], linewidth=2)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Softmax', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.legend(['x', '0.1', '0.9'])\n",
    "plt.show()"
   ],
   "id": "d21fadaab5925a69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Softmax函数是一个向量函数。所以我们可以看到各分量之间相互关系的变化。",
   "id": "cc8da396575d9f82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（平均平方差）",
   "id": "eb126281af182759"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:14.893762413Z",
     "start_time": "2026-01-19T04:05:14.447503865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSELoss(Loss):\n",
    "\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        mse = Tensor(np.mean(np.square(y.data - p.data)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad += -2 * (y.data - p.data) / len(y.data)\n",
    "\n",
    "        mse.gradient_fn = gradient_fn\n",
    "        mse.parents = {p}\n",
    "        return mse"
   ],
   "id": "519c13612e7dd806",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 优化器（随机梯度下降）",
   "id": "965400b15d5eafc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:15.076866233Z",
     "start_time": "2026-01-19T04:05:14.983780291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SGDOptimizer(Optimizer):\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.parameters:\n",
    "            p.data -= p.grad * self.lr"
   ],
   "id": "810e773279096b6e",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 神经元网络模型",
   "id": "ecd4551c263e788a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:15.384233410Z",
     "start_time": "2026-01-19T04:05:15.078491552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NNModel(Model):\n",
    "\n",
    "    def train(self, dataset, epochs):\n",
    "        self.layer.train()\n",
    "        dataset.train()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(dataset)):\n",
    "                features, labels = dataset[i]\n",
    "\n",
    "                predictions = self.layer(features)\n",
    "                loss = self.loss_fn(predictions, labels)\n",
    "\n",
    "                self.optimizer.reset()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "    def test(self, dataset):\n",
    "        self.layer.eval()\n",
    "        dataset.eval()\n",
    "\n",
    "        features, labels = dataset.items()\n",
    "        predictions = self.layer(features)\n",
    "        loss = self.loss_fn(predictions, labels)\n",
    "        return predictions, loss"
   ],
   "id": "638533dd9402b4c8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 设置",
   "id": "85749d831ac20117"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 学习率",
   "id": "898437a9590ab74e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:15.427990533Z",
     "start_time": "2026-01-19T04:05:15.394576128Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.01",
   "id": "4b7c678791e667dc",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 批大小",
   "id": "a47ede9d8538f2bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:15.475576949Z",
     "start_time": "2026-01-19T04:05:15.442916965Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 2",
   "id": "c348060b2bb80e72",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 轮次",
   "id": "7301b5a2aa1bd5d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:15.512960290Z",
     "start_time": "2026-01-19T04:05:15.477788370Z"
    }
   },
   "cell_type": "code",
   "source": "EPOCHS = 10",
   "id": "ddc9f472e538a4c4",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练",
   "id": "a9512865f4167872"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 迭代\n",
    "\n",
    "MNIST 手写数字识别是一个多元分类问题，所以让我们试一下用Softmax函数作为输出层激活函数怎么样。"
   ],
   "id": "512888b7ae3f2dad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:29.260697815Z",
     "start_time": "2026-01-19T04:05:15.517551397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = MNISTDataset('tinymnist.npz', BATCH_SIZE)\n",
    "layer = Sequential([Flatten(),\n",
    "                    Linear(dataset.shape()[0], 64),\n",
    "                    ReLU(),\n",
    "                    Dropout(),\n",
    "                    Linear(64, dataset.shape()[1]),\n",
    "                    Softmax()])\n",
    "loss_fn = MSELoss()\n",
    "optimizer = SGDOptimizer(layer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model = NNModel(layer, loss_fn, optimizer)\n",
    "model.train(dataset, EPOCHS)\n",
    "print(layer)"
   ],
   "id": "be0d4c5c9f755f35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten[]\n",
      "Linear[weight(64, 784); bias(64,)]\n",
      "ReLU[]\n",
      "Dropout[rate=0.2]\n",
      "Linear[weight(10, 64); bias(10,)]\n",
      "Softmax[]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "e8275b36f115139f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 测试",
   "id": "fb5eaf31986ab533"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T04:05:29.780668546Z",
     "start_time": "2026-01-19T04:05:29.358648252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions, loss = model.test(dataset)\n",
    "accuracy = dataset.estimate(predictions)\n",
    "print(f'accuracy: {accuracy:.2%}')"
   ],
   "id": "24602dd2f08ccce5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 87.30%\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "采用了输出层激活函数Softmax()后，准确率反而下降了一些。怎么回事？",
   "id": "cc32a9800367677b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 总结\n",
    "\n",
    "| 激活函数 |     主要用途     |                        优点 |                     缺点 |                推荐使用位置 |\n",
    "|------|:------------:|--------------------------:|-----------------------:|----------------------:|\n",
    "|ReLU| 默认首选，处理非线性特征 |      计算快；在正区间无梯度饱和，缓解梯度消失 |  负区间梯度为0，可能导致神经元“永久死亡” |              所有的中间隐藏层 |\n",
    "|Tanh|  处理具有正负值的数据  |     输出零中心化（均值为0），使下一层收敛更快 |      存在梯度饱和；计算涉及指数，开销大 |                   隐藏层 |\n",
    "|Sigmoid|   二元分类概率预测   | 将输出平滑压缩至(0, 1)区间；输出可解释为概率 | 严重的梯度饱和，导致梯度消失；输出均值不为0 |            二元分类任务的输出层 |\n",
    "|Softmax|   多元分类概率预测   |       处理多个类别的概率，确保概率总和为1 |  计算复杂；受极端数值影响大 | 多元分类任务的输出层 |"
   ],
   "id": "adea9267abd5dec2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

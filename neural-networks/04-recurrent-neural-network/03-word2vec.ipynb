{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 词向量\n",
    "\n",
    "我们已经实现了用**单热编码**来表示一个单词；使用**词袋**来表示一组相关的单词；使用**嵌入**来更有效地表示每个单词。\n",
    "\n",
    "嵌入的核心是使用网络模型训练过的权重来表示对应的单词。\n",
    "\n",
    "作为网络模型的参数，我们可以将权重看作模型在海量数据中挖掘出的“内在规则”。由于单热编码的特性（仅有一位为 1），在训练过程中，每个单词的语义规则被精确地压缩进了一个特定的权重切片中。因此我们认为这个权重切片包含了这个单词的特有信息，可以用来代表这个单词。\n",
    "\n",
    "如果打个比方的话，单热编码就好比是我们给每种花起个名字。无论是牡丹、还是玫瑰，都是独特的名字，可以让我们区别每种花；而嵌入权重就好比是我们调查过每种花后，给每种花写的简介。不仅可以用来区别每种花，还可以告诉我们每种花的特点。\n",
    "\n",
    "这种包含了单词信息的权重切片，被称作**词向量**（Word Embedding）。\n",
    "\n",
    "在上一个章节，我们已经完成了一种训练词向量的方法。使用的标签值是对照一个词袋（观众影评）的观众态度：喜欢，或者讨厌。因此，我们从这次训练中可以学习到的，就是每个单词所表达的喜欢，或者讨厌的情绪。以此为基础，我们可以从训练后的词向量中提取出近义词和反义词。\n",
    "\n",
    "现在，我们将尝试一种新的训练词向量的方法。使用的标签值也将是单词。\n",
    "\n",
    "---\n",
    "\n",
    "2013年，Google 的托马斯（Tomas）团队发布了 Word2Vec。它基于**分布置信假设**（Distributional Hypothesis），即：具有相似上下文的词，其语义也是相似的。\n",
    "\n",
    "**Word2Vec** 的核心思路是用文字训练文字，目标是用文字预测文字：\n",
    "\n",
    "* **连续词袋**（Continuous Bag-of-Words, CBOW）：通过上下文预测中心词；\n",
    "* **跳字**（Skip-gram）：通过中心词预测上下文。\n",
    "\n",
    "具体讲，比如数据集中的一条数据是这样一句话：“老鼠爱大米”。那么：\n",
    "\n",
    "* **连续词袋**使用“老”、“鼠”、“大”、“米”四个字组成的词袋（的单热编码）作为输入数据，使用“爱”这个字（的单热编码）作为标签值；\n",
    "* **跳字**则是使用“爱”这个字（的单热编码）作为输入数据，“老”、“鼠”、“大”、“米”四个字（的单热编码）分别作为标签值。\n",
    "\n",
    "形象地讲：\n",
    "\n",
    "* **连续词袋**是训练网络模型学习做填空题；\n",
    "* **跳字**是训练模型从一个词发散思维，做头脑风暴、思维导图。"
   ],
   "id": "9e3b77c72c43376c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.281752Z",
     "start_time": "2026-02-07T14:25:21.271396Z"
    }
   },
   "source": [
    "import csv\n",
    "import math\n",
    "import re\n",
    "from abc import abstractmethod, ABC\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(99)"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 基础架构",
   "id": "4ad3e91e8f5dd61f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 张量",
   "id": "76ffa09456a4b1d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.289079Z",
     "start_time": "2026-02-07T14:25:21.283306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.grad = np.zeros_like(self.data)\n",
    "        self.gradient_fn = lambda: None\n",
    "        self.parents = set()\n",
    "\n",
    "    def backward(self):\n",
    "        if self.gradient_fn:\n",
    "            self.gradient_fn()\n",
    "\n",
    "        for p in self.parents:\n",
    "            p.backward()\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return np.prod(self.data.shape[1:])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Tensor({self.data})'"
   ],
   "id": "98da1e7f4883cb6e",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础数据集",
   "id": "808f34399fedc7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.303577Z",
     "start_time": "2026-02-07T14:25:21.289522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dataset(ABC):\n",
    "\n",
    "    def __init__(self, batch_size=1):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.test_labels = self.test_features = None\n",
    "        self.train_labels = self.train_features = None\n",
    "\n",
    "        self.load()\n",
    "        self.train()\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        self.features = self.train_features\n",
    "        self.labels = self.train_labels\n",
    "\n",
    "    def eval(self):\n",
    "        self.features = self.test_features\n",
    "        self.labels = self.test_labels\n",
    "\n",
    "    def shape(self):\n",
    "        return Tensor(self.features).size, Tensor(self.labels).size\n",
    "\n",
    "    def items(self):\n",
    "        return Tensor(self.features), Tensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "\n",
    "        feature = Tensor(self.features[start: end])\n",
    "        label = Tensor(self.labels[start: end])\n",
    "        return feature, label\n",
    "\n",
    "    def estimate(self, predictions):\n",
    "        pass"
   ],
   "id": "3184c7ebd35741e4",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础层",
   "id": "9630f69ccfc5eadd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.311413Z",
     "start_time": "2026-02-07T14:25:21.305300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(ABC):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.training = True\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: Tensor):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return ''"
   ],
   "id": "c9430289f62a18cf",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础损失函数",
   "id": "a7d76d1f238e2f2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.316518Z",
     "start_time": "2026-02-07T14:25:21.312100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss(ABC):\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        return self.loss(p, y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        pass"
   ],
   "id": "3c54354f9cc55f52",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础优化器",
   "id": "440d33480b751ee8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.320468Z",
     "start_time": "2026-02-07T14:25:21.316916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Optimizer(ABC):\n",
    "\n",
    "    def __init__(self, parameters, lr):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "\n",
    "    def reset(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad = np.zeros_like(p.data)\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self):\n",
    "        pass"
   ],
   "id": "ca36d13a92575aee",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础模型",
   "id": "cba0d133a47f403"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.324401Z",
     "start_time": "2026-02-07T14:25:21.320801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(ABC):\n",
    "\n",
    "    def __init__(self, layer, loss_fn, optimizer):\n",
    "        self.layer = layer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, dataset, epochs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def test(self, dataset):\n",
    "        pass"
   ],
   "id": "9f11e2dd6492be7c",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据",
   "id": "3e3bc5aaf4aedca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### IMDB 数据集\n",
    "\n",
    "我们继续使用同样的 IMDB 数据集来训练 Word2Vec 词向量，但是只需要观众影评的部分。\n",
    "\n",
    "我们来实现一个采用 **连续词袋**（CBOW） 策略的网络模型。\n",
    "\n",
    "我们构建训练集的策略是：对每一条观众影评，我们每次截取 5 个单词。使用中间的单词的单热编码作为标签值；而剩余 4 个单词组成一个词袋，作为特征值。\n",
    "\n",
    "因此模型的预测值将不再是一个数值，而是和一个单热编码等长的 $n$ 个数值，这里的 $n$ 是词表的长度。\n",
    "\n",
    "我们据此也修改了**评估函数**（estimate），比较预测值（单热编码）对应的索引编码，和标签值（单热编码）对应的索引编码。"
   ],
   "id": "48a0c19bdc0c9ac0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.330415Z",
     "start_time": "2026-02-07T14:25:21.324834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IMDBDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        super().__init__()\n",
    "\n",
    "    def load(self):\n",
    "        self.reviews = []\n",
    "        self.sentiments = []\n",
    "        with open(self.filename, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for _, row in enumerate(reader):\n",
    "                self.reviews.append(row[0])\n",
    "                self.sentiments.append(row[1])\n",
    "\n",
    "        split_reviews = []\n",
    "        for line in self.reviews:\n",
    "            split_reviews.append(self.clean_text(line.lower()).split())\n",
    "\n",
    "        self.vocabulary = set(word for line in split_reviews for word in line)\n",
    "        self.word2index = {word: index for index, word in enumerate(self.vocabulary)}\n",
    "        self.index2word = {index: word for index, word in enumerate(self.vocabulary)}\n",
    "        self.tokens = [[self.word2index[word] for word in line if word in self.word2index] for line in split_reviews]\n",
    "\n",
    "        self.train_features = []\n",
    "        self.train_labels = []\n",
    "        for line in self.tokens[:-10]:\n",
    "            for index in range(len(line) - 4):\n",
    "                self.train_features.append([line[index], line[index + 1], line[index + 3], line[index + 4]])\n",
    "                self.train_labels.append(self.onehot(line[index + 2]))\n",
    "\n",
    "        self.test_features = []\n",
    "        self.test_labels = []\n",
    "        for line in self.tokens[-10:]:\n",
    "            for index in range(len(line) - 4):\n",
    "                self.test_features.append([line[index], line[index + 1], line[index + 3], line[index + 4]])\n",
    "                self.test_labels.append(self.onehot(line[index + 2]))\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "        return text\n",
    "\n",
    "    def encode(self, text):\n",
    "        words = self.clean_text(text.lower()).split()\n",
    "        return [self.word2index[word] for word in words]\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return \" \".join([self.index2word[index] for index in tokens])\n",
    "\n",
    "    def onehot(self, token):\n",
    "        ebd = np.zeros(len(self.vocabulary))\n",
    "        ebd[token] = 1\n",
    "        return ebd\n",
    "\n",
    "    @staticmethod\n",
    "    def argmax(vector):\n",
    "        return np.argmax(vector)\n",
    "\n",
    "    def estimate(self, predictions):\n",
    "        count = 0\n",
    "        for i in range(len(predictions)):\n",
    "            if self.argmax(predictions[i].data[0]) == self.argmax(self.labels[i].data):\n",
    "                count += 1\n",
    "        return count / len(predictions)"
   ],
   "id": "94e64b4c0eabcaff",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型",
   "id": "a7ec8d93ec84d28e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 线性层",
   "id": "615461506c3e6e7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.335586Z",
     "start_time": "2026-02-07T14:25:21.330753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.weight = Tensor(np.random.randn(out_size, in_size) * np.sqrt(2 / in_size))\n",
    "        self.bias = Tensor(np.zeros(out_size))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(x.data @ self.weight.data.T + self.bias.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.weight.grad += p.grad.T @ x.data\n",
    "            self.bias.grad += np.sum(p.grad, axis=0)\n",
    "            x.grad += p.grad @ self.weight.data\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.weight, self.bias]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Linear[weight{self.weight.data.shape}; bias{self.bias.data.shape}]'"
   ],
   "id": "36ee847b469bb5ff",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 顺序层",
   "id": "dd3f9a88069f81c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.339553Z",
     "start_time": "2026-02-07T14:25:21.335922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sequential(Layer):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "\n",
    "    def train(self):\n",
    "        for l in self.layers:\n",
    "            l.train()\n",
    "\n",
    "    def eval(self):\n",
    "        for l in self.layers:\n",
    "            l.eval()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join(str(l) for l in self.layers if str(l))"
   ],
   "id": "392c3f8e528297c9",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 嵌入层",
   "id": "6c9c5a3db3e716e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.343475Z",
     "start_time": "2026-02-07T14:25:21.339826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embedding(Layer):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.weight = Tensor(np.random.randn(embedding_size, vocabulary_size) * np.sqrt(2 / vocabulary_size))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(np.mean(self.weight.data.T[x.data], axis=1))\n",
    "\n",
    "        def gradient_fn():\n",
    "            if type(self.weight.grad) is not np.ndarray:\n",
    "                self.weight.grad = np.zeros_like(self.weight.data)\n",
    "            self.weight.grad.T[x.data] += p.grad / len(x.data)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self.weight}\n",
    "        return p\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Embedding[weight{self.weight.data.shape}; vocabulary={self.vocabulary_size}; embedding={self.embedding_size}]'"
   ],
   "id": "32a5c5fc4617938e",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sigmoid 激活函数",
   "id": "10446f336ec60817"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.347021Z",
     "start_time": "2026-02-07T14:25:21.343743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sigmoid(Layer):\n",
    "\n",
    "    def __init__(self, clip_range=(-100, 100)):\n",
    "        super().__init__()\n",
    "        self.clip_range = clip_range\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        z = np.clip(x.data, self.clip_range[0], self.clip_range[1])\n",
    "        p = Tensor(1 / (1 + np.exp(-z)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad += p.grad * p.data * (1 - p.data)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Sigmoid[]'"
   ],
   "id": "4d3c53da9f19f4be",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Softmax 激活函数",
   "id": "5ab330619c5d98d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.351025Z",
     "start_time": "2026-02-07T14:25:21.347330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Softmax(Layer):\n",
    "\n",
    "    def __init__(self, axis=-1):\n",
    "        super().__init__()\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        exp = np.exp(x.data - np.max(x.data, axis=self.axis, keepdims=True))\n",
    "        p = Tensor(exp / np.sum(exp, axis=self.axis, keepdims=True))\n",
    "\n",
    "        def gradient_fn():\n",
    "            grad = np.sum(p.data * p.grad, axis=self.axis, keepdims=True)\n",
    "            x.grad += p.data * (p.grad - grad)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Softmax[]'"
   ],
   "id": "183675d8e5912260",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（交叉熵）",
   "id": "15b1d6accf607c94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.355162Z",
     "start_time": "2026-02-07T14:25:21.351393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CELoss(Loss):\n",
    "\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        exp = np.exp(p.data - np.max(p.data, axis=-1, keepdims=True))\n",
    "        softmax = exp / np.sum(exp, axis=-1, keepdims=True)\n",
    "\n",
    "        log = np.log(np.clip(softmax, 1e-10, 1))\n",
    "        ce = Tensor(0 - np.sum(y.data * log) / len(y.data))\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad += (softmax - y.data) / len(y.data)\n",
    "\n",
    "        ce.gradient_fn = gradient_fn\n",
    "        ce.parents = {p}\n",
    "        return ce"
   ],
   "id": "fc09ece682436d0c",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（二元交叉熵）",
   "id": "fd6decedde0cfbfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.358632Z",
     "start_time": "2026-02-07T14:25:21.355418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BCELoss(Loss):\n",
    "\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        clipped = np.clip(p.data, 1e-7, 1 - 1e-7)\n",
    "        bce = Tensor(-np.mean(y.data * np.log(clipped) + (1 - y.data) * np.log(1 - clipped)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad += (clipped - y.data) / (clipped * (1 - clipped)) / len(y.data)\n",
    "\n",
    "        bce.gradient_fn = gradient_fn\n",
    "        bce.parents = {p}\n",
    "        return bce"
   ],
   "id": "648d5527ecd611e6",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 优化器（随机梯度下降）",
   "id": "3f0096e38462b2f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.362115Z",
     "start_time": "2026-02-07T14:25:21.358888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SGDOptimizer(Optimizer):\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.parameters:\n",
    "            p.data -= p.grad * self.lr"
   ],
   "id": "e9a556872b1df86",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 神经网络模型",
   "id": "e45bc59a4ddb16a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.365853Z",
     "start_time": "2026-02-07T14:25:21.362380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class W2VModel(Model):\n",
    "\n",
    "    def train(self, dataset, epochs):\n",
    "        self.layer.train()\n",
    "        dataset.train()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(dataset)):\n",
    "                features, labels = dataset[i]\n",
    "\n",
    "                predictions = self.layer(features)\n",
    "                loss = self.loss_fn(predictions, labels)\n",
    "                self.optimizer.reset()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "    def test(self, dataset):\n",
    "        self.layer.eval()\n",
    "        dataset.eval()\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(len(dataset)):\n",
    "            features, labels = dataset[i]\n",
    "            predictions.append(self.layer(features))\n",
    "        return predictions"
   ],
   "id": "82558b95c4a1d5be",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 设置",
   "id": "a0dc95f4aa75cc14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 学习率",
   "id": "eb496e2365188f53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.368981Z",
     "start_time": "2026-02-07T14:25:21.366124Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.01",
   "id": "725036a072c743a",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 轮次",
   "id": "37c577e2f3d1fa2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:21.372148Z",
     "start_time": "2026-02-07T14:25:21.369236Z"
    }
   },
   "cell_type": "code",
   "source": "EPOCHS = 100",
   "id": "9db52ae94644c258",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练",
   "id": "631dcfc126823cd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 迭代\n",
    "\n",
    "训练 Word2Vec 词向量，输出层的预测值将不再是一个数值，而是和单热编码长度（或者词表长度）相同。因此这是一个多元分类问题，我们将采用**交叉熵损失函数**（CELoss）。同时也不需要显式地使用输出层激活函数，CELoss 已经包括 SoftMax 激活函数的逻辑。"
   ],
   "id": "182c437e48259ef2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:26.927681Z",
     "start_time": "2026-02-07T14:25:21.372402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = IMDBDataset('tinyimdb.csv')\n",
    "layer = Sequential([Embedding(len(dataset.vocabulary), 32),\n",
    "                    Linear(32, len(dataset.vocabulary))])\n",
    "loss = CELoss()\n",
    "optimizer = SGDOptimizer(layer.parameters, lr=LEARNING_RATE)\n",
    "\n",
    "model = W2VModel(layer, loss, optimizer)\n",
    "model.train(dataset, EPOCHS)\n",
    "print(layer)"
   ],
   "id": "157fe17f92697e9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding[weight(32, 86); vocabulary=86; embedding=32]\n",
      "Linear[weight(86, 32); bias(86,)]\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "8ac58a2e86c018fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 测试\n",
    "\n",
    "使用一个非常小的数据集，通过 100 轮的快速训练，我们的网络模型已经可以成功预测出超过一半的中心词。充分显示出 Word2Vec 的思想逻辑是正确、有效的。"
   ],
   "id": "4e46ee55186c7c94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:26.939520Z",
     "start_time": "2026-02-07T14:25:26.928689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = model.test(dataset)\n",
    "print(f'Accuracy: {dataset.estimate(predictions)}')"
   ],
   "id": "661830cf3be02a43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.554140127388535\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 对比\n",
    "\n",
    "我们来实际地看一看网络模型的预测效果吧。"
   ],
   "id": "44c2bdb456cd2e76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:26.952659Z",
     "start_time": "2026-02-07T14:25:26.940291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features, labels = dataset.items()\n",
    "for i in range(len(predictions)):\n",
    "    pos = np.argmax(predictions[i].data[0])\n",
    "    print(f'Feature: {dataset.decode(features.data[i])} | '\n",
    "          f'Label: {dataset.decode([dataset.argmax(labels.data[i])])} | '\n",
    "          f'Prediction: {dataset.decode([dataset.argmax(predictions[i].data[0])])}')"
   ],
   "id": "1af0d2a1dccaa0ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: worst movie awful music | Label: with | Prediction: with\n",
      "Feature: movie with music the | Label: awful | Prediction: boring\n",
      "Feature: with awful the actor | Label: music | Prediction: soundtrack\n",
      "Feature: awful music actor did | Label: the | Prediction: the\n",
      "Feature: music the did a | Label: actor | Prediction: director\n",
      "Feature: the actor a boring | Label: did | Prediction: did\n",
      "Feature: actor did boring job | Label: a | Prediction: a\n",
      "Feature: did a job actress | Label: boring | Prediction: fantastic\n",
      "Feature: a boring actress director | Label: job | Prediction: job\n",
      "Feature: boring job director character | Label: actress | Prediction: actor\n",
      "Feature: job actress character screenplay | Label: director | Prediction: director\n",
      "Feature: actress director screenplay scene | Label: character | Prediction: character\n",
      "Feature: director character scene but | Label: screenplay | Prediction: actress\n",
      "Feature: character screenplay but or | Label: scene | Prediction: actress\n",
      "Feature: screenplay scene or it | Label: but | Prediction: music\n",
      "Feature: scene but it at | Label: or | Prediction: on\n",
      "Feature: but or at by | Label: it | Prediction: of\n",
      "Feature: i recommend film the | Label: this | Prediction: this\n",
      "Feature: recommend this the actress | Label: film | Prediction: film\n",
      "Feature: this film actress was | Label: the | Prediction: the\n",
      "Feature: film the was wonderful | Label: actress | Prediction: actor\n",
      "Feature: the actress wonderful and | Label: was | Prediction: was\n",
      "Feature: actress was and the | Label: wonderful | Prediction: wonderful\n",
      "Feature: was wonderful the music | Label: and | Prediction: actor\n",
      "Feature: wonderful and music was | Label: the | Prediction: the\n",
      "Feature: and the was amazing | Label: music | Prediction: story\n",
      "Feature: the music amazing actor | Label: was | Prediction: was\n",
      "Feature: music was actor director | Label: amazing | Prediction: excellent\n",
      "Feature: was amazing director character | Label: actor | Prediction: actress\n",
      "Feature: amazing actor character scene | Label: director | Prediction: actress\n",
      "Feature: actor director scene plot | Label: character | Prediction: character\n",
      "Feature: director character plot by | Label: scene | Prediction: screenplay\n",
      "Feature: character scene by was | Label: plot | Prediction: plot\n",
      "Feature: poor movie story and | Label: the | Prediction: the\n",
      "Feature: movie the and actor | Label: story | Prediction: character\n",
      "Feature: the story actor were | Label: and | Prediction: and\n",
      "Feature: story and were terrible | Label: actor | Prediction: plot\n",
      "Feature: and actor terrible i | Label: were | Prediction: were\n",
      "Feature: actor were i disappointed | Label: terrible | Prediction: terrible\n",
      "Feature: were terrible disappointed the | Label: i | Prediction: i\n",
      "Feature: terrible i the director | Label: disappointed | Prediction: disappointed\n",
      "Feature: i disappointed director actress | Label: the | Prediction: the\n",
      "Feature: disappointed the actress character | Label: director | Prediction: director\n",
      "Feature: the director character action | Label: actress | Prediction: actress\n",
      "Feature: director actress action screenplay | Label: character | Prediction: character\n",
      "Feature: actress character screenplay scene | Label: action | Prediction: director\n",
      "Feature: character action scene by | Label: screenplay | Prediction: plot\n",
      "Feature: action screenplay by is | Label: scene | Prediction: was\n",
      "Feature: excellent film saw this | Label: i | Prediction: i\n",
      "Feature: film i this time | Label: saw | Prediction: saw\n",
      "Feature: i saw time perfect | Label: this | Prediction: this\n",
      "Feature: saw this perfect performance | Label: time | Prediction: time\n",
      "Feature: this time performance by | Label: perfect | Prediction: fantastic\n",
      "Feature: time perfect by the | Label: performance | Prediction: performance\n",
      "Feature: perfect performance the actor | Label: by | Prediction: by\n",
      "Feature: performance by actor and | Label: the | Prediction: the\n",
      "Feature: by the and actress | Label: actor | Prediction: actor\n",
      "Feature: the actor actress director | Label: and | Prediction: and\n",
      "Feature: actor and director screenplay | Label: actress | Prediction: actress\n",
      "Feature: and actress screenplay scene | Label: director | Prediction: the\n",
      "Feature: actress director scene character | Label: screenplay | Prediction: screenplay\n",
      "Feature: director screenplay character his | Label: scene | Prediction: actress\n",
      "Feature: screenplay scene his her | Label: character | Prediction: plot\n",
      "Feature: boring movie poor effect | Label: with | Prediction: with\n",
      "Feature: movie with effect the | Label: poor | Prediction: amazing\n",
      "Feature: with poor the director | Label: effect | Prediction: visual\n",
      "Feature: poor effect director did | Label: the | Prediction: the\n",
      "Feature: effect the did a | Label: director | Prediction: director\n",
      "Feature: the director a awful | Label: did | Prediction: did\n",
      "Feature: director did awful job | Label: a | Prediction: a\n",
      "Feature: did a job actor | Label: awful | Prediction: wonderful\n",
      "Feature: a awful actor character | Label: job | Prediction: job\n",
      "Feature: awful job character actress | Label: actor | Prediction: actor\n",
      "Feature: job actor actress screenplay | Label: character | Prediction: character\n",
      "Feature: actor character screenplay music | Label: actress | Prediction: scene\n",
      "Feature: character actress music plot | Label: screenplay | Prediction: scene\n",
      "Feature: actress screenplay plot by | Label: music | Prediction: character\n",
      "Feature: screenplay music by was | Label: plot | Prediction: is\n",
      "Feature: music plot was is | Label: by | Prediction: by\n",
      "Feature: this film wonderful i | Label: was | Prediction: was\n",
      "Feature: film was i loved | Label: wonderful | Prediction: amazing\n",
      "Feature: was wonderful loved the | Label: i | Prediction: i\n",
      "Feature: wonderful i the plot | Label: loved | Prediction: enjoyed\n",
      "Feature: i loved plot and | Label: the | Prediction: the\n",
      "Feature: loved the and actress | Label: plot | Prediction: effect\n",
      "Feature: the plot actress the | Label: and | Prediction: and\n",
      "Feature: plot and the scene | Label: actress | Prediction: effect\n",
      "Feature: and actress scene was | Label: the | Prediction: the\n",
      "Feature: actress the was amazing | Label: scene | Prediction: and\n",
      "Feature: the scene amazing director | Label: was | Prediction: was\n",
      "Feature: scene was director character | Label: amazing | Prediction: boring\n",
      "Feature: was amazing character actor | Label: director | Prediction: recommend\n",
      "Feature: amazing director actor screenplay | Label: character | Prediction: character\n",
      "Feature: director character screenplay his | Label: actor | Prediction: actress\n",
      "Feature: character actor his her | Label: screenplay | Prediction: actress\n",
      "Feature: great movie actor and | Label: the | Prediction: the\n",
      "Feature: movie the and screenplay | Label: actor | Prediction: character\n",
      "Feature: the actor screenplay were | Label: and | Prediction: and\n",
      "Feature: actor and were excellent | Label: screenplay | Prediction: actress\n",
      "Feature: and screenplay excellent i | Label: were | Prediction: this\n",
      "Feature: screenplay were i enjoyed | Label: excellent | Prediction: wonderful\n",
      "Feature: were excellent enjoyed the | Label: i | Prediction: i\n",
      "Feature: excellent i the visual | Label: enjoyed | Prediction: enjoyed\n",
      "Feature: i enjoyed visual actress | Label: the | Prediction: the\n",
      "Feature: enjoyed the actress character | Label: visual | Prediction: screenplay\n",
      "Feature: the visual character scene | Label: actress | Prediction: actress\n",
      "Feature: visual actress scene script | Label: character | Prediction: director\n",
      "Feature: actress character script music | Label: scene | Prediction: director\n",
      "Feature: character scene music effect | Label: script | Prediction: action\n",
      "Feature: scene script effect or | Label: music | Prediction: plot\n",
      "Feature: i waste time the | Label: of | Prediction: of\n",
      "Feature: waste of the screenplay | Label: time | Prediction: time\n",
      "Feature: of time screenplay was | Label: the | Prediction: the\n",
      "Feature: time the was boring | Label: screenplay | Prediction: scene\n",
      "Feature: the screenplay boring and | Label: was | Prediction: was\n",
      "Feature: screenplay was and the | Label: boring | Prediction: awful\n",
      "Feature: was boring the scene | Label: and | Prediction: director\n",
      "Feature: boring and scene was | Label: the | Prediction: the\n",
      "Feature: and the was awful | Label: scene | Prediction: story\n",
      "Feature: the scene awful actor | Label: was | Prediction: was\n",
      "Feature: scene was actor actress | Label: awful | Prediction: excellent\n",
      "Feature: was awful actress character | Label: actor | Prediction: screenplay\n",
      "Feature: awful actor character screenplay | Label: actress | Prediction: director\n",
      "Feature: actor actress screenplay music | Label: character | Prediction: character\n",
      "Feature: actress character music effect | Label: screenplay | Prediction: action\n",
      "Feature: character screenplay effect by | Label: music | Prediction: plot\n",
      "Feature: best film fantastic soundtrack | Label: with | Prediction: with\n",
      "Feature: film with soundtrack the | Label: fantastic | Prediction: poor\n",
      "Feature: with fantastic the director | Label: soundtrack | Prediction: visual\n",
      "Feature: fantastic soundtrack director did | Label: the | Prediction: the\n",
      "Feature: soundtrack the did a | Label: director | Prediction: actress\n",
      "Feature: the director a perfect | Label: did | Prediction: did\n",
      "Feature: director did perfect job | Label: a | Prediction: a\n",
      "Feature: did a job actor | Label: perfect | Prediction: wonderful\n",
      "Feature: a perfect actor actress | Label: job | Prediction: job\n",
      "Feature: perfect job actress character | Label: actor | Prediction: actor\n",
      "Feature: job actor character scene | Label: actress | Prediction: actress\n",
      "Feature: actor actress scene screenplay | Label: character | Prediction: character\n",
      "Feature: actress character screenplay music | Label: scene | Prediction: action\n",
      "Feature: character scene music in | Label: screenplay | Prediction: screenplay\n",
      "Feature: scene screenplay in on | Label: music | Prediction: plot\n",
      "Feature: this movie terrible i | Label: was | Prediction: was\n",
      "Feature: movie was i hated | Label: terrible | Prediction: boring\n",
      "Feature: was terrible hated the | Label: i | Prediction: i\n",
      "Feature: terrible i the story | Label: hated | Prediction: hated\n",
      "Feature: i hated story and | Label: the | Prediction: the\n",
      "Feature: hated the and actor | Label: story | Prediction: story\n",
      "Feature: the story actor the | Label: and | Prediction: and\n",
      "Feature: story and the scene | Label: actor | Prediction: actor\n",
      "Feature: and actor scene was | Label: the | Prediction: the\n",
      "Feature: actor the was poor | Label: scene | Prediction: and\n",
      "Feature: the scene poor actress | Label: was | Prediction: was\n",
      "Feature: scene was actress director | Label: poor | Prediction: excellent\n",
      "Feature: was poor director character | Label: actress | Prediction: actress\n",
      "Feature: poor actress character screenplay | Label: director | Prediction: actor\n",
      "Feature: actress director screenplay action | Label: character | Prediction: character\n",
      "Feature: director character action by | Label: screenplay | Prediction: screenplay\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 近似词\n",
    "\n",
    "我们同样来看一看 Word2Vec 词向量会认为那些词比较相似。"
   ],
   "id": "1bbf4e10dc4b9d85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T14:25:26.972016Z",
     "start_time": "2026-02-07T14:25:26.957200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def similar(dataset, layer, target='excellent'):\n",
    "    target_index = dataset.word2index[target]\n",
    "    scores = {}\n",
    "\n",
    "    for word, index in dataset.word2index.items():\n",
    "        raw_diff = layer.layers[0].weight.data.T[index] - layer.layers[0].weight.data.T[target_index]\n",
    "        squared_diff = raw_diff ** 2\n",
    "        scores[word] = math.sqrt(sum(squared_diff))\n",
    "\n",
    "    return dict(sorted(scores.items(), key=lambda i: i[1])[:10])\n",
    "\n",
    "print(similar(dataset, layer, target='excellent'))\n",
    "print(similar(dataset, layer, target='terrible'))"
   ],
   "id": "cc0d4cfb481f9a9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'excellent': 0.0, 'fantastic': 5.793438066371971, 'good': 5.8148704204971615, 'great': 5.928235996432042, 'perfect': 6.0575236173255, 'best': 6.468919762945004, 'us': 6.563356752055503, 'wonderful': 6.6680588831054, 'amazing': 6.694282437507823, 'bad': 7.0203383091897065}\n",
      "{'terrible': 0.0, 'best': 6.246525151844197, 'poor': 6.539992043043173, 'love': 6.833738228015124, 'good': 7.058571501661191, 'bad': 7.278590385149035, 'watch': 7.286652618780295, 'worst': 7.2948139899956095, 'for': 7.511930830395485, 'boring': 7.516690112623038}\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "可以看出，Word2Vec 认为相似的单词并不全是同义词、或者近义词，甚至会是反义词。\n",
    "\n",
    "这是应为我们的训练标的（标签值）不再是喜欢、或者讨厌，而是可能和上下文一起使用的单词。我们训练的目标不再是单词表达的态度，而是单词之间的相关性。"
   ],
   "id": "f1b8ffb11d1fcfc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 课后练习\n",
    "\n",
    "修改数据集的构建方法，尝试训练一个**跳字** Word2Vec 词向量。"
   ],
   "id": "8ed30a76009ae3ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

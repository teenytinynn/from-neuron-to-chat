{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# å•çƒ­ç¼–ç \n",
    "\n",
    "åœ¨ç¬¬ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä»é›¶èµ·æ­¥ï¼Œåˆ›å»ºäº†ä¸€ä¸ªé¢„æµ‹å†°æ¿€æ·‹é”€é‡çš„**å¤šå±‚ç¥ç»ç½‘ç»œ**ï¼›åœ¨ç¬¬äºŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬äº²æ‰‹æ­å»ºäº†ä¸€ä¸ª**ç¥ç»ç½‘ç»œè®­ç»ƒæ¡†æ¶**ï¼Œæ”¯æŒå…¨è¿æ¥ç½‘ç»œï¼Œè§£å†³äº†æ•°å€¼å›å½’ä»»åŠ¡ï¼›åœ¨ç¬¬ä¸‰éƒ¨åˆ†ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æ‰©å±•äº†æ¡†æ¶ï¼Œä½¿å…¶å…·å¤‡äº†æ”¯æŒåˆ†ç±»ä»»åŠ¡ï¼Œå¤„ç†å¤šç»´åº¦æ•°æ®ï¼Œå’Œæå–å±€éƒ¨ç‰¹å¾ï¼ˆCNNï¼‰çš„èƒ½åŠ›ã€‚\n",
    "\n",
    "åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è¿˜åœç•™åœ¨å¤„ç†é™æ€æ•°æ®ã€â€œç¬æ—¶åœºæ™¯â€çš„é˜¶æ®µã€‚æ¨¡å‹å¤„ç†çš„æ¯ä¸€ç»„é”€é‡æ•°æ®ï¼Œè¯†åˆ«çš„æ¯ä¸€å¼ å›¾ç‰‡ï¼Œéƒ½æ˜¯å½¼æ­¤ç‹¬ç«‹çš„ä¸ªä½“ã€‚\n",
    "\n",
    "è¿˜æœ‰å¦ä¸€ç±»æ•°æ®ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º**åºåˆ—æ•°æ®**ï¼ˆSequence Dataï¼‰ã€‚è¿™ä¸€ç±»æ•°æ®ï¼Œæˆ‘ä»¬ä¸èƒ½åªçœ‹å½“å‰çš„ä¸€ç»„æ•°æ®ï¼Œè¿˜è¦å‚è€ƒä¹‹å‰çš„æ‰€æœ‰æ•°æ®ã€‚æ¯”å¦‚è‚¡ä»·ï¼Œæˆ‘ä»¬ä¸èƒ½åªçœ‹ä»Šå¤©çš„ä»·æ ¼ï¼Œè¿˜è¦å‚è€ƒä¹‹å‰å¾ˆé•¿æ—¶é—´çš„è‚¡ä»·å˜åŒ–æ¥åšåˆ†æã€‚\n",
    "\n",
    "åœ¨æ‰€æœ‰åºåˆ—æ•°æ®ä¸­ï¼Œæœ€è´´è¿‘äººç±»æ™ºèƒ½ã€ä¹Ÿæœ€å¤æ‚çš„ï¼Œè«è¿‡äºè¯­è¨€ã€‚\n",
    "\n",
    "è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ç»§ç»­æ‰©å……æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œè®­ç»ƒæ¡†æ¶ï¼Œå°è¯•å¤„ç†æ–‡å­—ä¿¡æ¯ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "æˆ‘ä»¬éœ€è¦é¢å¯¹çš„ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ï¼šå¦‚ä½•æ•°å­—åŒ–æ–‡å­—ä¿¡æ¯ã€‚\n",
    "\n",
    "ç¥ç»ç½‘ç»œåªèƒ½å¤„ç†æ•°å­—ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•å°†æ–‡å­—è½¬æ¢æˆæ•°å­—ã€‚\n",
    "\n",
    "ä¸€ç§æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯ï¼šæŠŠæ‰€æœ‰å•è¯æ’åˆ—èµ·æ¥ï¼Œåˆ†åˆ«ç»™å®ƒä»¬ä¸€ä¸ªç¼–å·ï¼Œç§°ä¸º**ç´¢å¼•ç¼–ç **ï¼ˆIndex-Based Encodingï¼‰ã€‚\n",
    "\n",
    "æ¯”å¦‚ï¼šå‡è®¾æ’åœ¨å‰ä¸‰ä½çš„å•è¯åˆ†åˆ«æ˜¯â€œä½ â€ã€â€œæˆ‘â€ã€â€œä»–â€ï¼Œé‚£ä¹ˆå®ƒä»¬çš„ç¼–å·å°±åˆ†åˆ«æ˜¯ 0ã€1ã€2ã€‚å¦‚æœæˆ‘ä»¬é‡‡ç”¨ GB-2312 æ±‰å­—åº“ï¼Œä¸€å…±æœ‰ 6763 ä¸ªæ±‰å­—ï¼Œå¯ä»¥åˆ†åˆ«ç¼–å·ä¸º 0 åˆ° 6762ã€‚\n",
    "\n",
    "ä½†æ˜¯**ç´¢å¼•ç¼–ç **ä»ç„¶ä¸é€‚ç”¨äºç¥ç»ç½‘ç»œï¼Œå› ä¸ºå¯èƒ½ä¼šè®©æ¨¡å‹è®¤ä¸º 1 ä»£è¡¨çš„â€œæˆ‘â€å¤§äº 0 ä»£è¡¨çš„â€œä½ â€ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "è¿™æ—¶å€™ï¼Œæˆ‘ä»¬åœ¨ä¸Šä¸€éƒ¨åˆ†çš„ MNIST æ•°æ®é›†ä¸­ä½¿ç”¨è¿‡çš„**å•çƒ­ç¼–ç **ï¼ˆOne-Hot Encodingï¼‰æ­£å¥½å¯ä»¥æ´¾ä¸Šç”¨åœºã€‚\n",
    "\n",
    "**å•çƒ­ç¼–ç **çš„æ ¸å¿ƒæ€æƒ³éå¸¸ç›´è§‚ï¼šå®ƒå°†æ¯ä¸€ä¸ªç±»åˆ«æ˜ å°„ä¸ºä¸€ä¸ªå‘é‡ï¼Œå‘é‡çš„é•¿åº¦å’Œç±»åˆ«çš„æ€»æ•°ç›¸åŒã€‚åœ¨è¿™ä¸ªå‘é‡ä¸­ï¼Œåªæœ‰ä¸€ä¸ªä½ç½®çš„å€¼æ˜¯ 1ï¼Œè€Œå…¶ä½™æ‰€æœ‰ä½ç½®çš„å€¼éƒ½æ˜¯ 0ã€‚\n",
    "\n",
    "è¿˜ä»¥ GB-2312 æ±‰å­—åº“ä¸ºä¾‹ã€‚ä¸€å…± 6763 ä¸ªæ±‰å­—ï¼Œæ‰€ä»¥æ¯ä¸ªæ±‰å­—å°†è¢«æ˜ å°„åˆ°ä¸€ä¸ªé•¿åº¦ä¸º 6763 çš„å‘é‡ã€‚â€œä½ â€çš„ç¼–ç åªæœ‰ç¬¬ 1 ä¸ªä½ç½®æ˜¯ 1ï¼Œâ€œæˆ‘â€çš„ç¼–ç åªæœ‰ç¬¬ 2 ä¸ªä½ç½®æ˜¯ 1ã€‚\n",
    "\n",
    "|  è¯æ±‡  |  ç´¢å¼•ç¼–ç   |          å•çƒ­ç¼–ç å‘é‡          |\n",
    "|:----:|:------:|:------------------------:|\n",
    "|  ä½    |   0    | [1, 0, 0, 0, 0, ... , 0] |\n",
    "|  æˆ‘   |   1    | [0, 1, 0, 0, 0, ... , 0] |\n",
    "|  ä»–   |   2    | [0, 0, 1, 0, 0, ... , 0] |\n",
    "\n",
    "<div style=\"border-left: 4px solid #4CAF50; background:#f9f9f9; padding:10px; margin:10px 0;\">\n",
    "<strong>ğŸ’¡ æç¤ºï¼š</strong> å•çƒ­ç¼–ç è™½ç„¶ç®€å•å¥½ç”¨ï¼Œä½†å½“è¯è¡¨è¾¾åˆ°å‡ ä¸‡ç”šè‡³å‡ åä¸‡æ—¶ï¼Œå‘é‡ä¼šå˜å¾—æå…¶å·¨å¤§ï¼Œä½†æ˜¯ç¨€ç–ã€‚\n",
    "</div>"
   ],
   "id": "9e3b77c72c43376c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-28T12:41:33.053061Z",
     "start_time": "2026-01-28T12:41:33.046755Z"
    }
   },
   "source": [
    "import csv\n",
    "import re\n",
    "from abc import abstractmethod, ABC\n",
    "import numpy as np\n",
    "from numpy.ma.core import argmax\n",
    "\n",
    "np.random.seed(99)"
   ],
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## åŸºç¡€æ¶æ„",
   "id": "d2807c9c7c24ade7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### å¼ é‡",
   "id": "76ffa09456a4b1d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:41:33.060794Z",
     "start_time": "2026-01-28T12:41:33.053524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.grad = np.zeros_like(self.data)\n",
    "        self.gradient_fn = lambda: None\n",
    "        self.parents = set()\n",
    "\n",
    "    def backward(self):\n",
    "        if self.gradient_fn:\n",
    "            self.gradient_fn()\n",
    "\n",
    "        for p in self.parents:\n",
    "            p.backward()\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return np.prod(self.data.shape[1:])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Tensor({self.data})'"
   ],
   "id": "98da1e7f4883cb6e",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### åŸºç¡€æ•°æ®é›†",
   "id": "808f34399fedc7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:41:33.065449Z",
     "start_time": "2026-01-28T12:41:33.061063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dataset(ABC):\n",
    "\n",
    "    def __init__(self, batch_size=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.load()\n",
    "        self.train()\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        self.features = self.train_features\n",
    "        self.labels = self.train_labels\n",
    "\n",
    "    def eval(self):\n",
    "        self.features = self.test_features\n",
    "        self.labels = self.test_labels\n",
    "\n",
    "    def shape(self):\n",
    "        return Tensor(self.features).size, Tensor(self.labels).size\n",
    "\n",
    "    def items(self):\n",
    "        return Tensor(self.features), Tensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "\n",
    "        feature = Tensor(self.features[start: end])\n",
    "        label = Tensor(self.labels[start: end])\n",
    "        return feature, label\n",
    "\n",
    "    def estimate(self, predictions):\n",
    "        pass"
   ],
   "id": "3184c7ebd35741e4",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## æ•°æ®",
   "id": "4c2e8dcfac6097b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### IMDB æ•°æ®é›†\n",
    "\n",
    "åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ¥è‡ª IMDB çš„å½±è¯„æ•°æ®é›†ã€‚å½“ç„¶ï¼Œä¸ºäº†åŠ å¿«æ¨¡å‹è®­ç»ƒé€Ÿåº¦ï¼Œæˆ‘ä»¬ä¾æ—§åˆ¶ä½œäº†ä¸€ä¸ªè¿·ä½ ç‰ˆæœ¬ï¼šTinyIMDBã€‚\n",
    "\n",
    "IMDB æ•°æ®é›†çš„æ¯ä¸ªæ ·æœ¬åŒ…æ‹¬ä¸¤ä¸ªæ•°æ®ï¼š\n",
    "\n",
    "* **è§‚ä¼—å½±è¯„**ï¼šè¿™æ˜¯ä¸€æ®µç”±è§‚ä¼—ä¹¦å†™çš„æ–‡å­—ä¿¡æ¯ï¼›\n",
    "* **è§‚ä¼—æ€åº¦**ï¼šè§‚ä¼—ç»™å‡ºçš„è¯„ä»·ï¼ˆâ€œå–œæ¬¢â€ï¼Œ æˆ–è€…â€œè®¨åŒâ€ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "åœ¨åŠ è½½ IMDB æ•°æ®é›†æ—¶ï¼Œæˆ‘ä»¬å°†å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼š\n",
    "\n",
    "* **æ•°æ®æ¸…æ´—**ï¼šæ•°æ®æ¸…æ´—çš„ç›®çš„åœ¨äºå»é™¤è§‚ä¼—å½±è¯„ä¸­çš„ HTML æ ‡ç­¾å’Œæ ‡ç‚¹ç¬¦å·ï¼›\n",
    "* **æ„å»ºè¯è¡¨**ï¼šç»Ÿè®¡æ•°æ®é›†ç”¨åˆ°çš„æ‰€æœ‰å•è¯ï¼Œæ±‡æ€»æˆå•è¯åˆ—è¡¨ï¼›\n",
    "* **ç´¢å¼•ç¼–ç **ï¼šå¯¹å•è¯åˆ—è¡¨è¿›è¡Œç´¢å¼•ç¼–ç ï¼›\n",
    "\n",
    "æ•°æ®åŠ è½½ä»¥åï¼Œæˆ‘ä»¬åˆ›å»ºäº†å‡ ä¸ªåˆ—è¡¨å±æ€§ï¼š\n",
    "\n",
    "* **è¯è¡¨**ï¼ˆvocabularyï¼‰ï¼šæ‰€æœ‰å•è¯çš„æ±‡æ€»\n",
    "* **ç´¢å¼•è¡¨**ï¼š\n",
    "    * **æ­£å‘ç´¢å¼•è¡¨**ï¼ˆword2indexï¼‰ï¼šä»å•è¯åˆ°ç´¢å¼•ç¼–ç çš„å¯¹ç…§è¡¨\n",
    "    * **åå‘ç´¢å¼•è¡¨**ï¼ˆindex2wordï¼‰ï¼šä»ç´¢å¼•ç¼–ç åˆ°å•è¯çš„å¯¹ç…§è¡¨\n",
    "* **è¯å…ƒè¡¨**ï¼ˆtokensï¼‰ï¼šå°†è§‚ä¼—å½±è¯„è½¬æ¢ä¸ºç´¢å¼•ç¼–ç \n",
    "\n",
    "åœ¨ IMDB æ•°æ®é›†é‡Œï¼Œæˆ‘ä»¬è¿˜æä¾›äº†å‡ ä¸ªå’Œç¼–ç æœ‰å…³çš„å‡½æ•°ï¼š\n",
    "\n",
    "* **ç¼–ç å‡½æ•°**ï¼ˆencodeï¼‰ï¼šè¿”å›å•è¯çš„ç´¢å¼•ç¼–ç ï¼›\n",
    "* **è§£ç å‡½æ•°**ï¼ˆdecodeï¼‰ï¼šè¿”å›ç´¢å¼•ç¼–ç å¯¹åº”çš„å•è¯ï¼›\n",
    "* **å•çƒ­ç¼–ç å‡½æ•°**ï¼ˆonehotï¼‰ï¼šè¿”å›ç´¢å¼•ç¼–ç çš„å•çƒ­ç¼–ç ï¼›\n",
    "* **ç´¢å¼•ç¼–ç å‡½æ•°**ï¼ˆargmaxï¼‰ï¼šè¿”å›å•çƒ­ç¼–ç å¯¹åº”çš„ç´¢å¼•ç¼–ç ã€‚\n",
    "\n",
    "å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬æ²¡æœ‰è¿›ä¸€æ­¥å°†**è¯å…ƒè¡¨**ï¼ˆtokensï¼‰è½¬æ¢æˆå•çƒ­ç¼–ç ï¼Œä¸ç„¶æˆ‘ä»¬éœ€è¦å·¨é‡çš„å†…å­˜ç©ºé—´æ¥ä¿å­˜ã€‚æˆ‘ä»¬æä¾›äº†**å•çƒ­ç¼–ç å‡½æ•°**ï¼ˆonehotï¼‰åœ¨éœ€è¦çš„æ—¶å€™å¯ä»¥å®æ—¶å°†ç´¢å¼•ç¼–ç è½¬æ¢ä¸ºå•çƒ­ç¼–ç ã€‚"
   ],
   "id": "9091f1a11751a31f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:41:33.071401Z",
     "start_time": "2026-01-28T12:41:33.065830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IMDBDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        super().__init__()\n",
    "\n",
    "    def load(self):\n",
    "        self.reviews = []\n",
    "        self.sentiments = []\n",
    "        # åŠ è½½æ•°æ®\n",
    "        with open(self.filename, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for _, row in enumerate(reader):\n",
    "                self.reviews.append(row[0])\n",
    "                self.sentiments.append(row[1])\n",
    "\n",
    "        split_reviews = []\n",
    "        for line in self.reviews:\n",
    "            # æ¸…æ´—ã€åˆ†è¯\n",
    "            split_reviews.append(self.clean_text(line.lower()).split())\n",
    "\n",
    "        # æ„å»ºè¯è¡¨\n",
    "        self.vocabulary = set(word for line in split_reviews for word in line)\n",
    "        # ç´¢å¼•ç¼–ç \n",
    "        self.word2index = {word: index for index, word in enumerate(self.vocabulary)}\n",
    "        self.index2word = {index: word for index, word in enumerate(self.vocabulary)}\n",
    "        # å°†æ‰€æœ‰å½±è¯„è½¬æ¢ä¸ºç´¢å¼•ç¼–ç \n",
    "        self.tokens = [[self.word2index[word] for word in line if word in self.word2index] for line in split_reviews]\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        # å»é™¤ HTML æ ‡ç­¾\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        # å»é™¤æ ‡ç‚¹ç¬¦å·\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "        return text\n",
    "\n",
    "    def train(self):\n",
    "        self.features = [list(set(index)) for index in self.tokens[:-10]]\n",
    "        self.labels = [0 if index == \"negative\" else 1 for index in self.sentiments[:-10]]\n",
    "\n",
    "    def eval(self):\n",
    "        self.features = [list(set(index)) for index in self.tokens[-10:]]\n",
    "        self.labels = [0 if index == \"negative\" else 1 for index in self.sentiments[-10:]]\n",
    "\n",
    "    def encode(self, text):\n",
    "        words = self.clean_text(text.lower()).split()\n",
    "        return [self.word2index[word] for word in words]\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return \" \".join([self.index2word[index] for index in tokens])\n",
    "\n",
    "    def onehot(self, token):\n",
    "        ebd = np.zeros(len(self.vocabulary))\n",
    "        ebd[token] = 1\n",
    "        return ebd\n",
    "\n",
    "    @staticmethod\n",
    "    def argmax(vector):\n",
    "        return np.argmax(vector)"
   ],
   "id": "43f534698d141456",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## éªŒè¯",
   "id": "87aebc33b105f956"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### æµ‹è¯•\n",
    "\n",
    "è®©æˆ‘ä»¬åŠ è½½æ•°æ®é›†ï¼Œçœ‹ä¸€çœ‹ç¬¬ä¸€æ¡æ•°æ®ï¼ˆè§‚ä¼—å½±è¯„å’Œè§‚ä¼—æ€åº¦ï¼‰æ˜¯ä»€ä¹ˆã€‚"
   ],
   "id": "4e46ee55186c7c94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:41:33.085948Z",
     "start_time": "2026-01-28T12:41:33.071661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# åŠ è½½æ•°æ®é›†\n",
    "dataset = IMDBDataset('tinyimdb.csv')\n",
    "print(f'vocabulary count: {len(dataset.vocabulary)}')\n",
    "print(f'review: \"{dataset.reviews[0]}\"')\n",
    "print(f'tokens: {dataset.tokens[0]}')\n",
    "print(f'sentiment: \"{dataset.sentiments[0]}\"')"
   ],
   "id": "661830cf3be02a43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary count: 86\n",
      "review: \"this movie was excellent. i enjoyed the plot and acting. the character was wonderful. recommend. screenplay actor actress by is a\"\n",
      "tokens: [36, 80, 83, 20, 64, 46, 61, 59, 50, 8, 61, 37, 83, 12, 23, 3, 14, 76, 5, 11, 38]\n",
      "sentiment: \"positive\"\n"
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ç´¢å¼•ç¼–ç ",
   "id": "e0a13a0c7a482a22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:41:33.102698Z",
     "start_time": "2026-01-28T12:41:33.087379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = 'i recommend this film'\n",
    "print(f'message: \"{message}\"')\n",
    "\n",
    "tokens = dataset.encode(message)\n",
    "print(f'encode: {tokens}')\n",
    "print(f'decode: \"{dataset.decode(tokens)}\"')"
   ],
   "id": "5b7484692489287b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message: \"i recommend this film\"\n",
      "encode: [64, 23, 36, 79]\n",
      "decode: \"i recommend this film\"\n"
     ]
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### å•çƒ­ç¼–ç ",
   "id": "18016f89e7e8f54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T12:41:33.112325Z",
     "start_time": "2026-01-28T12:41:33.103435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word = 'recommend'\n",
    "print(f'word: \"{word}\"')\n",
    "\n",
    "token = dataset.word2index[word]\n",
    "print(f'token: {token}')\n",
    "\n",
    "onehot = dataset.onehot(token)\n",
    "print(f'onehot: {onehot}')\n",
    "print(f'argmax: {dataset.argmax(onehot)}')"
   ],
   "id": "f7f49a9fa055aafa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: \"recommend\"\n",
      "token: 23\n",
      "onehot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "argmax: 23\n"
     ]
    }
   ],
   "execution_count": 150
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Long Short Term Memory",
   "id": "9e3b77c72c43376c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:09.587612198Z",
     "start_time": "2025-12-25T05:16:09.546245027Z"
    }
   },
   "source": [
    "import csv\n",
    "import math\n",
    "import re\n",
    "from abc import abstractmethod, ABC\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(99)"
   ],
   "outputs": [],
   "execution_count": 339
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Foundation",
   "id": "4ad3e91e8f5dd61f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tensor",
   "id": "76ffa09456a4b1d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:09.935004801Z",
     "start_time": "2025-12-25T05:16:09.598092993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.grad = None\n",
    "        self.gradient_fn = lambda: None\n",
    "        self.parents = set()\n",
    "\n",
    "    def backward(self):\n",
    "        if self.gradient_fn:\n",
    "            self.gradient_fn()\n",
    "\n",
    "        for p in self.parents:\n",
    "            p.backward()\n",
    "\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "\n",
    "    def size(self):\n",
    "        return np.prod(self.data.shape[1:])\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.data)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        p = Tensor(self.data + other.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.grad = p.grad\n",
    "            other.grad = p.grad\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self, other}\n",
    "        return p\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        p = Tensor(self.data * other.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.grad = p.grad * other.data\n",
    "            other.grad = p.grad * self.data\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self, other}\n",
    "        return p\n",
    "\n",
    "    def concat(self, other, axis):\n",
    "        p = Tensor(np.concatenate([self.data, other.data], axis=axis))\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.grad, other.grad = np.split(p.grad, [self.data.shape[axis]], axis=axis)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self, other}\n",
    "        return p"
   ],
   "id": "98da1e7f4883cb6e",
   "outputs": [],
   "execution_count": 340
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Dataset",
   "id": "808f34399fedc7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:10.604977544Z",
     "start_time": "2025-12-25T05:16:10.099699046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dataset(ABC):\n",
    "\n",
    "    def __init__(self, batch_size=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.load()\n",
    "        self.train()\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        self.features = self.train_features\n",
    "        self.labels = self.train_labels\n",
    "\n",
    "    def eval(self):\n",
    "        self.features = self.test_features\n",
    "        self.labels = self.test_labels\n",
    "\n",
    "    def shape(self):\n",
    "        return Tensor(self.features).size(), Tensor(self.labels).size()\n",
    "\n",
    "    def items(self):\n",
    "        return Tensor(self.features), Tensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "        return Tensor(self.features[start: end]), Tensor(self.labels[start: end])\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimate(self, predictions):\n",
    "        pass"
   ],
   "id": "3184c7ebd35741e4",
   "outputs": [],
   "execution_count": 341
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Layer",
   "id": "9630f69ccfc5eadd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:10.984114077Z",
     "start_time": "2025-12-25T05:16:10.664282545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(ABC):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.training = True\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, *args):\n",
    "        pass\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "    def __str__(self):\n",
    "        return ''"
   ],
   "id": "c9430289f62a18cf",
   "outputs": [],
   "execution_count": 342
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Loss Function",
   "id": "a7d76d1f238e2f2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:11.348401041Z",
     "start_time": "2025-12-25T05:16:11.023808583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        pass"
   ],
   "id": "3c54354f9cc55f52",
   "outputs": [],
   "execution_count": 343
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Optimizer",
   "id": "440d33480b751ee8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:11.768420259Z",
     "start_time": "2025-12-25T05:16:11.674590968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Optimizer(ABC):\n",
    "\n",
    "    def __init__(self, parameters, lr):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self):\n",
    "        pass"
   ],
   "id": "ca36d13a92575aee",
   "outputs": [],
   "execution_count": 344
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Model",
   "id": "cba0d133a47f403"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:12.295303270Z",
     "start_time": "2025-12-25T05:16:12.007610517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(ABC):\n",
    "\n",
    "    def __init__(self, layer, loss, optimizer):\n",
    "        self.layer = layer\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, dataset, epochs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def test(self, dataset):\n",
    "        pass"
   ],
   "id": "9f11e2dd6492be7c",
   "outputs": [],
   "execution_count": 345
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data",
   "id": "3e3bc5aaf4aedca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RNN Dataset",
   "id": "48a0c19bdc0c9ac0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:12.708849819Z",
     "start_time": "2025-12-25T05:16:12.361763494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNNDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        super().__init__()\n",
    "\n",
    "    def load(self):\n",
    "        self.reviews = []\n",
    "        self.sentiments = []\n",
    "        with open(self.filename, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for _, row in enumerate(reader):\n",
    "                self.reviews.append(row[0])\n",
    "                self.sentiments.append(row[1])\n",
    "\n",
    "        split_reviews = []\n",
    "        for line in self.reviews:\n",
    "            split_reviews.append(self.clean_text(line.lower()).split())\n",
    "\n",
    "        self.vocabulary = set(word for line in split_reviews for word in line)\n",
    "        self.word2index = {word: index for index, word in enumerate(self.vocabulary)}\n",
    "        self.index2word = {index: word for index, word in enumerate(self.vocabulary)}\n",
    "        self.tokens = [[self.word2index[word] for word in line if word in self.word2index] for line in split_reviews]\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "        return text\n",
    "\n",
    "    def train(self):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        for line in self.tokens[:-10]:\n",
    "            for index in range(len(line) - 4):\n",
    "                self.features.append(line[index: index + 4])\n",
    "                self.labels.append(self.onehot(line[index + 4]))\n",
    "    def eval(self):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        for line in self.tokens[-10:]:\n",
    "            for index in range(len(line) - 4):\n",
    "                self.features.append(line[index: index + 4])\n",
    "                self.labels.append(self.onehot(line[index + 4]))\n",
    "\n",
    "    def encode(self, text):\n",
    "        words = self.clean_text(text.lower()).split()\n",
    "        return [self.word2index[word] for word in words]\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return \" \".join([self.index2word[index] for index in tokens])\n",
    "\n",
    "    def onehot(self, token):\n",
    "        ebd = np.zeros(len(self.vocabulary))\n",
    "        ebd[token] = 1\n",
    "        return ebd\n",
    "\n",
    "    @staticmethod\n",
    "    def argmax(vector):\n",
    "        return [np.argmax(vector)]\n",
    "\n",
    "    def estimate(self, predictions):\n",
    "        count = 0\n",
    "        for i in range(len(predictions)):\n",
    "            if self.argmax(predictions[i].data[0]) == self.argmax(self.labels[i].data):\n",
    "                count += 1\n",
    "        return count / len(predictions)"
   ],
   "id": "94e64b4c0eabcaff",
   "outputs": [],
   "execution_count": 346
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "a7ec8d93ec84d28e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Layer",
   "id": "615461506c3e6e7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:12.859733202Z",
     "start_time": "2025-12-25T05:16:12.763927156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.weight = Tensor(np.random.rand(out_size, in_size) / in_size)\n",
    "        self.bias = Tensor(np.zeros(out_size))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(x.data @ self.weight.data.T + self.bias.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.weight.grad = p.grad.T @ x.data / len(x.data)\n",
    "            self.bias.grad = np.sum(p.grad, axis=0) / len(x.data)\n",
    "            x.grad = p.grad @ self.weight.data\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self.weight, self.bias, x}\n",
    "        return p\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight, self.bias]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'weight: {self.weight}\\nbias: {self.bias}'"
   ],
   "id": "36ee847b469bb5ff",
   "outputs": [],
   "execution_count": 347
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sequential Layer",
   "id": "dd3f9a88069f81c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.124756108Z",
     "start_time": "2025-12-25T05:16:12.865228733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sequential(Layer):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "\n",
    "    def train(self):\n",
    "        for l in self.layers:\n",
    "            l.train()\n",
    "\n",
    "    def eval(self):\n",
    "        for l in self.layers:\n",
    "            l.eval()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join(str(l) for l in self.layers if str(l))"
   ],
   "id": "392c3f8e528297c9",
   "outputs": [],
   "execution_count": 348
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Embedding Layer",
   "id": "6c9c5a3db3e716e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.167475734Z",
     "start_time": "2025-12-25T05:16:13.141618539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embedding(Layer):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_size, axis=1):\n",
    "        super().__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.axis = axis\n",
    "\n",
    "        self.weight = Tensor(np.random.rand(embedding_size, vocabulary_size) / vocabulary_size)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(np.sum(self.weight.data.T[x.data], axis=self.axis))\n",
    "\n",
    "        def gradient_fn():\n",
    "            if self.weight.grad is None:\n",
    "                self.weight.grad = np.zeros_like(self.weight.data)\n",
    "            self.weight.grad.T[x.data] += p.grad\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self.weight}\n",
    "        return p\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]"
   ],
   "id": "4e15300e5ed869d8",
   "outputs": [],
   "execution_count": 349
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ReLU Activation Function",
   "id": "8b160d6f6ddf2e40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.200402192Z",
     "start_time": "2025-12-25T05:16:13.172281769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReLU(Layer):\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(np.maximum(0, x.data))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad = (p.data > 0) * p.grad\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p"
   ],
   "id": "56103804f52a80e5",
   "outputs": [],
   "execution_count": 350
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tanh Activation Function",
   "id": "e69fc543bc7eabba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.217926919Z",
     "start_time": "2025-12-25T05:16:13.206057121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tanh(Layer):\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(np.tanh(x.data))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad = p.grad * (1 - p.data ** 2)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p"
   ],
   "id": "65ee9ee722441a67",
   "outputs": [],
   "execution_count": 351
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sigmoid Activation Function",
   "id": "10446f336ec60817"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.239487473Z",
     "start_time": "2025-12-25T05:16:13.222801373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sigmoid(Layer):\n",
    "\n",
    "    def __init__(self, clip_range=(-100, 100)):\n",
    "        super().__init__()\n",
    "        self.clip_range = clip_range\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        z = np.clip(x.data, self.clip_range[0], self.clip_range[1])\n",
    "        p = Tensor(1 / (1 + np.exp(-z)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad = p.grad * p.data * (1 - p.data)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p"
   ],
   "id": "4d3c53da9f19f4be",
   "outputs": [],
   "execution_count": 352
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Softmax Activation Function",
   "id": "5ab330619c5d98d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.267463701Z",
     "start_time": "2025-12-25T05:16:13.244640324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Softmax(Layer):\n",
    "\n",
    "    def __init__(self, axis=1):\n",
    "        super().__init__()\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        exp = np.exp(x.data - np.max(x.data, axis=self.axis, keepdims=True))\n",
    "        p = Tensor(exp / np.sum(exp, axis=self.axis, keepdims=True))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad = np.zeros_like(x.data)\n",
    "            for idx in range(x.data.shape[0]):\n",
    "                itm = p.data[idx].reshape(-1, 1)\n",
    "                x.grad[idx] = (np.diagflat(itm) - itm @ itm.T) @ p.grad[idx]\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p"
   ],
   "id": "183675d8e5912260",
   "outputs": [],
   "execution_count": 353
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LSTM Layer",
   "id": "b158f94f5e60969"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.303743819Z",
     "start_time": "2025-12-25T05:16:13.272571220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTM(Layer):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = Embedding(vocabulary_size, embedding_size)\n",
    "        self.forget_gate = Linear(embedding_size * 2, embedding_size)\n",
    "        self.input_gate = Linear(embedding_size * 2, embedding_size)\n",
    "        self.output_gate = Linear(embedding_size * 2, embedding_size)\n",
    "        self.cell_update = Linear(embedding_size * 2, embedding_size)\n",
    "        self.output = Linear(embedding_size, vocabulary_size)\n",
    "        self.sigmoid = Sigmoid()\n",
    "        self.tanh = Tanh()\n",
    "\n",
    "        self.layers = [self.embedding,\n",
    "                       self.forget_gate,\n",
    "                       self.input_gate,\n",
    "                       self.output_gate,\n",
    "                       self.cell_update,\n",
    "                       self.output,\n",
    "                       self.sigmoid,\n",
    "                       self.tanh]\n",
    "\n",
    "    def __call__(self, x: Tensor, c: Tensor, h: Tensor):\n",
    "        return self.forward(x, c, h)\n",
    "\n",
    "    def forward(self, x: Tensor, c: Tensor, h: Tensor):\n",
    "        if not c:\n",
    "            c = Tensor(np.zeros((1, self.embedding_size)))\n",
    "        if not h:\n",
    "            h = Tensor(np.zeros((1, self.embedding_size)))\n",
    "\n",
    "        embedding_feature = self.embedding(x)\n",
    "        concat_feature = self.tanh(embedding_feature.concat(h, axis=1))\n",
    "        forget_hidden = self.sigmoid(self.forget_gate(concat_feature))\n",
    "        input_hidden = self.sigmoid(self.input_gate(concat_feature))\n",
    "        output_hidden = self.sigmoid(self.output_gate(concat_feature))\n",
    "        cell_hidden = self.tanh(self.cell_update(concat_feature))\n",
    "        cell_feature = forget_hidden * c + input_hidden * cell_hidden\n",
    "        hidden_feature = output_hidden * self.tanh(cell_feature)\n",
    "\n",
    "        return (self.output(hidden_feature),\n",
    "                Tensor(cell_feature.data),\n",
    "                Tensor(hidden_feature.data))\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]"
   ],
   "id": "6082d7ebc8cd4abf",
   "outputs": [],
   "execution_count": 354
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MSE Loss Function",
   "id": "5336c80dc1eb204c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.415178458Z",
     "start_time": "2025-12-25T05:16:13.308881183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSELoss(Loss):\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        mse = Tensor(((p.data - y.data) ** 2).mean())\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad = (p.data - y.data) * 2\n",
    "\n",
    "        mse.gradient_fn = gradient_fn\n",
    "        mse.parents = {p}\n",
    "        return mse"
   ],
   "id": "75aaca7706d55538",
   "outputs": [],
   "execution_count": 355
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cross Entropy Loss Function",
   "id": "15b1d6accf607c94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.475565805Z",
     "start_time": "2025-12-25T05:16:13.417493775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CELoss:\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        exp = np.exp(p.data - np.max(p.data, axis=-1, keepdims=True))\n",
    "        softmax = exp / np.sum(exp, axis=-1, keepdims=True)\n",
    "\n",
    "        log = np.log(np.clip(softmax, 1e-10, 1))\n",
    "        ce = Tensor(0 - np.sum(y.data * log) / len(p.data))\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad = (softmax - y.data) / len(p.data)\n",
    "\n",
    "        ce.gradient_fn = gradient_fn\n",
    "        ce.parents = {p}\n",
    "        return ce"
   ],
   "id": "fc09ece682436d0c",
   "outputs": [],
   "execution_count": 356
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Binary Cross Entropy Loss Function",
   "id": "fd6decedde0cfbfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.501008417Z",
     "start_time": "2025-12-25T05:16:13.483493491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BCELoss:\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        clipped = np.clip(p.data, 1e-7, 1 - 1e-7)\n",
    "        bce = Tensor(-np.mean(y.data * np.log(clipped)\n",
    "                              + (1 - y.data) * np.log(1 - clipped)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad = (clipped - y.data) / (clipped * (1 - clipped)) * len(p.data)\n",
    "\n",
    "        bce.gradient_fn = gradient_fn\n",
    "        bce.parents = {p}\n",
    "        return bce"
   ],
   "id": "648d5527ecd611e6",
   "outputs": [],
   "execution_count": 357
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SGD Optimizer",
   "id": "3f0096e38462b2f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.530331270Z",
     "start_time": "2025-12-25T05:16:13.507163985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SGDOptimizer(Optimizer):\n",
    "\n",
    "    def backward(self):\n",
    "        for p in self.parameters:\n",
    "            p.data -= p.grad * self.lr"
   ],
   "id": "e9a556872b1df86",
   "outputs": [],
   "execution_count": 358
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LSTM Neural Network Model",
   "id": "e45bc59a4ddb16a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.553592590Z",
     "start_time": "2025-12-25T05:16:13.534429112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMModel(Model):\n",
    "\n",
    "    def train(self, dataset, epochs):\n",
    "        layer.train()\n",
    "        dataset.train()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            cell = hidden = None\n",
    "            for i in range(len(dataset)):\n",
    "                feature, label = dataset[i]\n",
    "\n",
    "                prediction, cell, hidden = self.layer(feature,\n",
    "                                                      cell,\n",
    "                                                      hidden)\n",
    "                error = self.loss(prediction,\n",
    "                                  label)\n",
    "\n",
    "                error.backward()\n",
    "                self.optimizer.backward()\n",
    "\n",
    "    def test(self, dataset):\n",
    "        layer.eval()\n",
    "        dataset.eval()\n",
    "\n",
    "        predictions = []\n",
    "        cell = hidden = None\n",
    "        for i in range(len(dataset)):\n",
    "            feature, label = dataset[i]\n",
    "            prediction, cell, hidden = self.layer(feature,\n",
    "                                                  cell,\n",
    "                                                  hidden)\n",
    "            predictions.append(prediction)\n",
    "        return predictions"
   ],
   "id": "82558b95c4a1d5be",
   "outputs": [],
   "execution_count": 359
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "a0dc95f4aa75cc14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Learning Rate",
   "id": "eb496e2365188f53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.570285356Z",
     "start_time": "2025-12-25T05:16:13.558067440Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.01",
   "id": "725036a072c743a",
   "outputs": [],
   "execution_count": 360
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Epoch",
   "id": "37c577e2f3d1fa2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:13.590397515Z",
     "start_time": "2025-12-25T05:16:13.572413339Z"
    }
   },
   "cell_type": "code",
   "source": "EPOCHS = 10",
   "id": "9db52ae94644c258",
   "outputs": [],
   "execution_count": 361
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "631dcfc126823cd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Iteration Training",
   "id": "182c437e48259ef2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:44.931494926Z",
     "start_time": "2025-12-25T05:16:13.604416144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = RNNDataset('reviews.csv')\n",
    "layer = LSTM(len(dataset.vocabulary), 64)\n",
    "loss = CELoss()\n",
    "optimizer = SGDOptimizer(layer.parameters(),\n",
    "                         lr=LEARNING_RATE)\n",
    "\n",
    "model = LSTMModel(layer,\n",
    "                  loss,\n",
    "                  optimizer)\n",
    "model.train(dataset,\n",
    "            EPOCHS)"
   ],
   "id": "157fe17f92697e9c",
   "outputs": [],
   "execution_count": 362
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing",
   "id": "8ac58a2e86c018fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Estimating",
   "id": "4e46ee55186c7c94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:45.194528579Z",
     "start_time": "2025-12-25T05:16:44.951900657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = model.test(dataset)\n",
    "\n",
    "print(f'Accuracy: {dataset.estimate(predictions)}')"
   ],
   "id": "661830cf3be02a43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14012738853503184\n"
     ]
    }
   ],
   "execution_count": 363
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Comparing Labels and Predictions",
   "id": "44c2bdb456cd2e76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T05:16:45.382186719Z",
     "start_time": "2025-12-25T05:16:45.198075719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features, labels = dataset.items()\n",
    "for i in range(len(predictions)):\n",
    "    pos = np.argmax(predictions[i].data[0])\n",
    "    print(f'Feature: {dataset.decode(features.data[i])} | '\n",
    "          f'Label: {dataset.decode(dataset.argmax(labels.data[i]))} | '\n",
    "          f'Prediction: {dataset.decode(dataset.argmax(predictions[i].data[0]))}')"
   ],
   "id": "1af0d2a1dccaa0ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: worst movie with awful | Label: music | Prediction: the\n",
      "Feature: movie with awful music | Label: the | Prediction: the\n",
      "Feature: with awful music the | Label: actor | Prediction: the\n",
      "Feature: awful music the actor | Label: did | Prediction: the\n",
      "Feature: music the actor did | Label: a | Prediction: the\n",
      "Feature: the actor did a | Label: boring | Prediction: the\n",
      "Feature: actor did a boring | Label: job | Prediction: the\n",
      "Feature: did a boring job | Label: actress | Prediction: the\n",
      "Feature: a boring job actress | Label: director | Prediction: the\n",
      "Feature: boring job actress director | Label: character | Prediction: the\n",
      "Feature: job actress director character | Label: screenplay | Prediction: actress\n",
      "Feature: actress director character screenplay | Label: scene | Prediction: the\n",
      "Feature: director character screenplay scene | Label: but | Prediction: by\n",
      "Feature: character screenplay scene but | Label: or | Prediction: by\n",
      "Feature: screenplay scene but or | Label: it | Prediction: by\n",
      "Feature: scene but or it | Label: at | Prediction: by\n",
      "Feature: but or it at | Label: by | Prediction: by\n",
      "Feature: i recommend this film | Label: the | Prediction: the\n",
      "Feature: recommend this film the | Label: actress | Prediction: the\n",
      "Feature: this film the actress | Label: was | Prediction: the\n",
      "Feature: film the actress was | Label: wonderful | Prediction: the\n",
      "Feature: the actress was wonderful | Label: and | Prediction: the\n",
      "Feature: actress was wonderful and | Label: the | Prediction: the\n",
      "Feature: was wonderful and the | Label: music | Prediction: the\n",
      "Feature: wonderful and the music | Label: was | Prediction: the\n",
      "Feature: and the music was | Label: amazing | Prediction: the\n",
      "Feature: the music was amazing | Label: actor | Prediction: the\n",
      "Feature: music was amazing actor | Label: director | Prediction: actress\n",
      "Feature: was amazing actor director | Label: character | Prediction: the\n",
      "Feature: amazing actor director character | Label: scene | Prediction: actress\n",
      "Feature: actor director character scene | Label: plot | Prediction: the\n",
      "Feature: director character scene plot | Label: by | Prediction: by\n",
      "Feature: character scene plot by | Label: was | Prediction: by\n",
      "Feature: poor movie the story | Label: and | Prediction: the\n",
      "Feature: movie the story and | Label: actor | Prediction: the\n",
      "Feature: the story and actor | Label: were | Prediction: the\n",
      "Feature: story and actor were | Label: terrible | Prediction: the\n",
      "Feature: and actor were terrible | Label: i | Prediction: the\n",
      "Feature: actor were terrible i | Label: disappointed | Prediction: the\n",
      "Feature: were terrible i disappointed | Label: the | Prediction: the\n",
      "Feature: terrible i disappointed the | Label: director | Prediction: the\n",
      "Feature: i disappointed the director | Label: actress | Prediction: the\n",
      "Feature: disappointed the director actress | Label: character | Prediction: the\n",
      "Feature: the director actress character | Label: action | Prediction: the\n",
      "Feature: director actress character action | Label: screenplay | Prediction: the\n",
      "Feature: actress character action screenplay | Label: scene | Prediction: by\n",
      "Feature: character action screenplay scene | Label: by | Prediction: by\n",
      "Feature: action screenplay scene by | Label: is | Prediction: by\n",
      "Feature: excellent film i saw | Label: this | Prediction: the\n",
      "Feature: film i saw this | Label: time | Prediction: by\n",
      "Feature: i saw this time | Label: perfect | Prediction: by\n",
      "Feature: saw this time perfect | Label: performance | Prediction: by\n",
      "Feature: this time perfect performance | Label: by | Prediction: by\n",
      "Feature: time perfect performance by | Label: the | Prediction: the\n",
      "Feature: perfect performance by the | Label: actor | Prediction: the\n",
      "Feature: performance by the actor | Label: and | Prediction: the\n",
      "Feature: by the actor and | Label: actress | Prediction: the\n",
      "Feature: the actor and actress | Label: director | Prediction: the\n",
      "Feature: actor and actress director | Label: screenplay | Prediction: the\n",
      "Feature: and actress director screenplay | Label: scene | Prediction: the\n",
      "Feature: actress director screenplay scene | Label: character | Prediction: the\n",
      "Feature: director screenplay scene character | Label: his | Prediction: by\n",
      "Feature: screenplay scene character his | Label: her | Prediction: by\n",
      "Feature: boring movie with poor | Label: effect | Prediction: the\n",
      "Feature: movie with poor effect | Label: the | Prediction: the\n",
      "Feature: with poor effect the | Label: director | Prediction: the\n",
      "Feature: poor effect the director | Label: did | Prediction: the\n",
      "Feature: effect the director did | Label: a | Prediction: the\n",
      "Feature: the director did a | Label: awful | Prediction: the\n",
      "Feature: director did a awful | Label: job | Prediction: the\n",
      "Feature: did a awful job | Label: actor | Prediction: the\n",
      "Feature: a awful job actor | Label: character | Prediction: the\n",
      "Feature: awful job actor character | Label: actress | Prediction: the\n",
      "Feature: job actor character actress | Label: screenplay | Prediction: actress\n",
      "Feature: actor character actress screenplay | Label: music | Prediction: the\n",
      "Feature: character actress screenplay music | Label: plot | Prediction: by\n",
      "Feature: actress screenplay music plot | Label: by | Prediction: by\n",
      "Feature: screenplay music plot by | Label: was | Prediction: by\n",
      "Feature: music plot by was | Label: is | Prediction: by\n",
      "Feature: this film was wonderful | Label: i | Prediction: the\n",
      "Feature: film was wonderful i | Label: loved | Prediction: the\n",
      "Feature: was wonderful i loved | Label: the | Prediction: the\n",
      "Feature: wonderful i loved the | Label: plot | Prediction: the\n",
      "Feature: i loved the plot | Label: and | Prediction: the\n",
      "Feature: loved the plot and | Label: actress | Prediction: the\n",
      "Feature: the plot and actress | Label: the | Prediction: the\n",
      "Feature: plot and actress the | Label: scene | Prediction: the\n",
      "Feature: and actress the scene | Label: was | Prediction: the\n",
      "Feature: actress the scene was | Label: amazing | Prediction: actress\n",
      "Feature: the scene was amazing | Label: director | Prediction: the\n",
      "Feature: scene was amazing director | Label: character | Prediction: actress\n",
      "Feature: was amazing director character | Label: actor | Prediction: the\n",
      "Feature: amazing director character actor | Label: screenplay | Prediction: the\n",
      "Feature: director character actor screenplay | Label: his | Prediction: the\n",
      "Feature: character actor screenplay his | Label: her | Prediction: by\n",
      "Feature: great movie the actor | Label: and | Prediction: the\n",
      "Feature: movie the actor and | Label: screenplay | Prediction: the\n",
      "Feature: the actor and screenplay | Label: were | Prediction: the\n",
      "Feature: actor and screenplay were | Label: excellent | Prediction: the\n",
      "Feature: and screenplay were excellent | Label: i | Prediction: the\n",
      "Feature: screenplay were excellent i | Label: enjoyed | Prediction: the\n",
      "Feature: were excellent i enjoyed | Label: the | Prediction: the\n",
      "Feature: excellent i enjoyed the | Label: visual | Prediction: the\n",
      "Feature: i enjoyed the visual | Label: actress | Prediction: the\n",
      "Feature: enjoyed the visual actress | Label: character | Prediction: the\n",
      "Feature: the visual actress character | Label: scene | Prediction: the\n",
      "Feature: visual actress character scene | Label: script | Prediction: the\n",
      "Feature: actress character scene script | Label: music | Prediction: by\n",
      "Feature: character scene script music | Label: effect | Prediction: by\n",
      "Feature: scene script music effect | Label: or | Prediction: by\n",
      "Feature: i waste of time | Label: the | Prediction: the\n",
      "Feature: waste of time the | Label: screenplay | Prediction: the\n",
      "Feature: of time the screenplay | Label: was | Prediction: the\n",
      "Feature: time the screenplay was | Label: boring | Prediction: the\n",
      "Feature: the screenplay was boring | Label: and | Prediction: the\n",
      "Feature: screenplay was boring and | Label: the | Prediction: the\n",
      "Feature: was boring and the | Label: scene | Prediction: the\n",
      "Feature: boring and the scene | Label: was | Prediction: the\n",
      "Feature: and the scene was | Label: awful | Prediction: the\n",
      "Feature: the scene was awful | Label: actor | Prediction: the\n",
      "Feature: scene was awful actor | Label: actress | Prediction: actress\n",
      "Feature: was awful actor actress | Label: character | Prediction: actress\n",
      "Feature: awful actor actress character | Label: screenplay | Prediction: the\n",
      "Feature: actor actress character screenplay | Label: music | Prediction: by\n",
      "Feature: actress character screenplay music | Label: effect | Prediction: by\n",
      "Feature: character screenplay music effect | Label: by | Prediction: by\n",
      "Feature: best film with fantastic | Label: soundtrack | Prediction: the\n",
      "Feature: film with fantastic soundtrack | Label: the | Prediction: the\n",
      "Feature: with fantastic soundtrack the | Label: director | Prediction: the\n",
      "Feature: fantastic soundtrack the director | Label: did | Prediction: the\n",
      "Feature: soundtrack the director did | Label: a | Prediction: the\n",
      "Feature: the director did a | Label: perfect | Prediction: the\n",
      "Feature: director did a perfect | Label: job | Prediction: the\n",
      "Feature: did a perfect job | Label: actor | Prediction: the\n",
      "Feature: a perfect job actor | Label: actress | Prediction: the\n",
      "Feature: perfect job actor actress | Label: character | Prediction: the\n",
      "Feature: job actor actress character | Label: scene | Prediction: actress\n",
      "Feature: actor actress character scene | Label: screenplay | Prediction: the\n",
      "Feature: actress character scene screenplay | Label: music | Prediction: by\n",
      "Feature: character scene screenplay music | Label: in | Prediction: by\n",
      "Feature: scene screenplay music in | Label: on | Prediction: by\n",
      "Feature: this movie was terrible | Label: i | Prediction: the\n",
      "Feature: movie was terrible i | Label: hated | Prediction: the\n",
      "Feature: was terrible i hated | Label: the | Prediction: the\n",
      "Feature: terrible i hated the | Label: story | Prediction: the\n",
      "Feature: i hated the story | Label: and | Prediction: the\n",
      "Feature: hated the story and | Label: actor | Prediction: the\n",
      "Feature: the story and actor | Label: the | Prediction: the\n",
      "Feature: story and actor the | Label: scene | Prediction: the\n",
      "Feature: and actor the scene | Label: was | Prediction: the\n",
      "Feature: actor the scene was | Label: poor | Prediction: the\n",
      "Feature: the scene was poor | Label: actress | Prediction: the\n",
      "Feature: scene was poor actress | Label: director | Prediction: the\n",
      "Feature: was poor actress director | Label: character | Prediction: the\n",
      "Feature: poor actress director character | Label: screenplay | Prediction: by\n",
      "Feature: actress director character screenplay | Label: action | Prediction: by\n",
      "Feature: director character screenplay action | Label: by | Prediction: by\n"
     ]
    }
   ],
   "execution_count": 364
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

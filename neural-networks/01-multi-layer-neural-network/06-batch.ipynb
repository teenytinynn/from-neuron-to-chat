{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 批次\n",
    "\n",
    "目前为止，在模型训练的过程中，我们每次取一条数据进行迭代。事实上，得益于NumPy数组的矢量并行运算能力，我们可以一次把多条数据送入迭代。这种迭代方式称为**批次梯度下降**（Batch Gradient Descent）。相对应地，每次一条数据的迭代方式称为**随机梯度下降**（Stochastic Gradient Descent）。\n",
    "\n",
    "批次又可以分为：\n",
    "* **全批次**（Full Batch）：就是一次把所有训练数据全部送入迭代。实践中很少使用全批次进行训练，因为需要大量的内存，运算速度会非常缓慢。\n",
    "* **小批次**（Mini-batch）：就是每次把数条数据送入迭代。小批次充分地利用了NumPy（或者其他计算库）的矢量并行运算能力，是目前常规的模型训练方式。\n",
    "\n",
    "全批次每次迭代都可以从全部数据进行学习，因此可以保持正确的收敛方向，所以全批次训练的收敛速度较快。相对应的，随机梯度下降每次迭代只能从一条数据进行学习，因此梯度变化较大，收敛方向左右摇摆，所以随机梯度下降的收敛速度较慢。而小批次处于两者之间比较平衡的位置，这也是小批次训练比较常用的另一个原因。\n",
    "\n",
    "## 泛化\n",
    "\n",
    "**泛化**（Generalization）是评价模型训练效果的一个重要指标。即模型可以对新数据进行合理、有效的推理的能力。简单地讲，就是一个在训练数据上表现良好的模型，是否可以在验证数据上同样有好的表现。\n",
    "\n",
    "通常来讲，泛化能力来自于对多样化的数据进行学习。因此随机梯度下降的训练方式通常可以带来更好的模型泛化能力；小批次训练次之；全批次训练更次之。\n",
    "\n",
    "泛化能力差一般有两种表现：\n",
    "* **欠拟合**（Underfitting）：模型在训练数据上表现就很差，在验证数据上表现也很差。通常是因为训练数据不足，或者模型过于简单。\n",
    "* **过拟合**（Overfitting）：模型在训练数据上接近优异，但在验证数据上上表现糟糕。通常是因为模型过于复杂，从训练数据中学习到了过多的、没有代表性的细节。"
   ],
   "id": "a1e60f68f1965aed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.195696057Z",
     "start_time": "2025-12-28T03:36:53.997388897Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "a2cac2228ddf353e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据集",
   "id": "9649bc0800a008fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 训练数据：特征、标签",
   "id": "8cd5507771bf641f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.305077620Z",
     "start_time": "2025-12-28T03:36:54.219145459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_features = np.array([[22.5, 72.0],\n",
    "                           [31.4, 45.0],\n",
    "                           [19.8, 85.0],\n",
    "                           [27.6, 63]])\n",
    "\n",
    "train_labels = np.array([[95],\n",
    "                        [210],\n",
    "                        [70],\n",
    "                        [155]])"
   ],
   "id": "79a53313fe79b770",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 验证数据：特征、标签",
   "id": "16f59bb9d2dfe1da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.413055258Z",
     "start_time": "2025-12-28T03:36:54.310214958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_features = np.array([[28.1, 58.0]])\n",
    "test_labels = np.array([[165]])"
   ],
   "id": "aeb2b926b7f4755d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型",
   "id": "a8657a3b1bd1a54b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 参数：权重、偏差",
   "id": "f1281f278a55cfb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.439024671Z",
     "start_time": "2025-12-28T03:36:54.416912222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight = np.ones([1, 2]) / 2\n",
    "bias = np.zeros(1)"
   ],
   "id": "305379a0adbd7223",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理函数（前向传播）",
   "id": "ef231771ee4703f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.462747762Z",
     "start_time": "2025-12-28T03:36:54.442597396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward(x, w, b):\n",
    "    return x @ w.T + b"
   ],
   "id": "f14e65ca9ef7cfb3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（平均平方差）",
   "id": "776600dc63470990"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.489312806Z",
     "start_time": "2025-12-28T03:36:54.465855969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mse_loss(p, y):\n",
    "    return ((p - y) ** 2).mean()"
   ],
   "id": "7cd0be4542f4780a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 梯度函数\n",
    "\n",
    "为了适应批次，梯度函数返回梯度的平均值，作为整个批次的梯度。"
   ],
   "id": "cdb405f2bc7270fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.527420973Z",
     "start_time": "2025-12-28T03:36:54.499132677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient(p, y):\n",
    "    return 2 * (p - y) / len(y)"
   ],
   "id": "ca1ff2b6e82c91ce",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 超参数：学习率",
   "id": "5c67d65ca82cafb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.554481141Z",
     "start_time": "2025-12-28T03:36:54.534618678Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.00001",
   "id": "9738f26d930f41bf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 反向函数（反向传播）",
   "id": "293ac1ea11b8571b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.581008484Z",
     "start_time": "2025-12-28T03:36:54.561784518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward(x, d, w, b):\n",
    "    w -= d.T @ x * LEARNING_RATE\n",
    "    b -= np.sum(d, axis=0) * LEARNING_RATE\n",
    "    return w, b"
   ],
   "id": "18b6e280eafe78e8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练",
   "id": "85b49bdb85eb6e32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 超参数：批大小\n",
    "\n",
    "作为我们的第二个超参数，**批大小**（Batch Size）定义了每个批次所采用的训练数据的数量。"
   ],
   "id": "bef048b34fd432b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.609294450Z",
     "start_time": "2025-12-28T03:36:54.585782699Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 2",
   "id": "7295eba469428166",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 迭代\n",
    "\n",
    "从下面的代码可以看出，采用了小批次训练后，可以更快地完成一轮迭代。"
   ],
   "id": "fcbfda65370f475f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.710891577Z",
     "start_time": "2025-12-28T03:36:54.619029239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(0, len(train_features), BATCH_SIZE):\n",
    "    # 每次读入一个批次需要的多个训练数据：特征、标签\n",
    "    features = train_features[i: i + BATCH_SIZE]\n",
    "    labels = train_labels[i: i + BATCH_SIZE]\n",
    "\n",
    "    # 同时对多个训练数据进行推理\n",
    "    predictions = forward(features, weight, bias)\n",
    "    # 计算多个训练数据的梯度平均值\n",
    "    delta = gradient(predictions, labels)\n",
    "    # 用梯度平均值更新一次参数\n",
    "    weight, bias = backward(features, delta, weight, bias)\n",
    "\n",
    "print(f\"weight: {weight}\")\n",
    "print(f\"bias: {bias}\")"
   ],
   "id": "8681b00a4a2d6a81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[0.59388172 0.68104165]]\n",
      "bias: [0.00327249]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "667f4085d8ca746e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理",
   "id": "964b247c7aa0e415"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:54.826513747Z",
     "start_time": "2025-12-28T03:36:54.735704426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = forward(test_features, weight, bias)\n",
    "\n",
    "print(f'predictions: {predictions}')"
   ],
   "id": "1fc7dba8f5d58b55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [[56.19176426]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 评估",
   "id": "ff1785b3003364f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T03:36:55.011856046Z",
     "start_time": "2025-12-28T03:36:54.832817722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "error = mse_loss(predictions, test_labels)\n",
    "\n",
    "print(f'error: {error}')"
   ],
   "id": "9a09acc7c763806d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 11839.232164432306\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "从验证的结果看，小批次训练一轮迭代的次数更少，但是收敛速度也相应地稍差。",
   "id": "273cf90ecccd6794"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# 学习率\n",
    "\n",
    "在上一个章节，我们尝试了使用梯度下降的方法进行模型训练。结果一顿操作猛如虎，为啥准确度还严重恶化了呢？\n",
    "\n",
    "原因只有一个：步子迈得太大啦！\n",
    "\n",
    "-----------------\n",
    "\n",
    "梯度的本质是损失函数对模型参数的偏导数，是损失函数曲线在某一点的切线斜率。它是下降的方向，并不是下降的幅度。\n",
    "\n",
    "梯度很大，只代表道路很陡峭，不代表步子应该很大。\n",
    "\n",
    "步子太大，可能直接越过函数的最低点，造成损失值在最低点的左右震荡，无法收敛。最终导致模型训练失败。\n",
    "\n",
    "-----------------\n",
    "\n",
    "为此我们引进一个控制梯度的比例，称为**学习率**（Learning Rate）。这样梯度下降的公式变为：\n",
    "\n",
    "$$\n",
    "w_{new} = w_{old} - \\eta \\cdot \\nabla J(w_{old})\n",
    "$$\n",
    "\n",
    "其中$\\eta$为学习率。通过调整学习率，我们可以控制模型训练的步调。既不应太小，造成损失函数收敛太慢；也不能太大，造成损失函数无法收敛。\n",
    "\n",
    "## 超参数\n",
    "\n",
    "学习率是我们遇到的第一个**超参数**（Hyperparameter）。\n",
    "\n",
    "我们已经知道模型参数包括权重和偏差。模型参数是模型训练的对象；而超参数则是我们控制模型训练步调的参数，比如学习率是我们控制梯度下降步调的参数。\n",
    "\n",
    "超参数并不会随着模型训练得到优化，而是需要在模型训练开始前根据数据、经验等实际情况人为设定；并根据模型训练的效果进行调整，以期获得最佳训练结果。这个不断测试、调整超参数的过程，被称为**调参**（Tuning）。"
   ],
   "id": "8b1718296e14f742"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:46.819435178Z",
     "start_time": "2025-12-29T14:49:46.799494070Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "c790c2847a5addf8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据",
   "id": "239f4cdf3b19b187"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 特征、标签",
   "id": "ed890d7484ee20a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:46.969723206Z",
     "start_time": "2025-12-29T14:49:46.834208648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature = np.array([28.1, 58.0])\n",
    "label = np.array([165])"
   ],
   "id": "6c1dd66a30855524",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型",
   "id": "9d51956d4698a34e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 参数：权重、偏差",
   "id": "d537395bac936f2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.076373678Z",
     "start_time": "2025-12-29T14:49:47.019336427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight = np.ones([1, 2]) / 2\n",
    "bias = np.zeros(1)"
   ],
   "id": "81298db1421a07bd",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理函数（前向传播）",
   "id": "e2b9dc3ebbffe209"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.127291956Z",
     "start_time": "2025-12-29T14:49:47.094072286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward(x, w, b):\n",
    "    return x @ w.T + b"
   ],
   "id": "659e728278131e0c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（平均平方差）",
   "id": "91ba7f0c0077c7b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.204016703Z",
     "start_time": "2025-12-29T14:49:47.138388553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mse_loss(p, y):\n",
    "    return ((y - p) ** 2).mean()"
   ],
   "id": "33403dc359850248",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 梯度函数",
   "id": "f0f1a1e8e62cb1f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.371510013Z",
     "start_time": "2025-12-29T14:49:47.276068928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient(p, y):\n",
    "    return - 2 * (y - p)"
   ],
   "id": "6159e0137e7326b3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 反向函数（反向传播）\n",
    "\n",
    "改进后的反向函数利用学习率调整模型训练的幅度。"
   ],
   "id": "782e08c9239c7fca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.398117749Z",
     "start_time": "2025-12-29T14:49:47.375420837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward(x, d, w, b, lr):\n",
    "    w -= d * x * lr\n",
    "    b -= np.sum(d) * lr\n",
    "    return w, b"
   ],
   "id": "18301d372b2cdaf1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "e38110a19341a207"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 超参数：学习率\n",
    "\n",
    "学习率的设定是一个比较人为、主观的步骤，并且需要通过调参的过程来优化。通常的做法是从一个初始值（比如：0.1）开始，逐步缩小（比如：0.01、0.001）并尝试，以期找到合适的学习率。\n",
    "\n",
    "在我们的例子中，通过观察在上一个章节中，没有学习率的情况下梯度下降的幅度，我们选择了一个相对较小的值。"
   ],
   "id": "a3e5cb6e8d818a73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.417601053Z",
     "start_time": "2025-12-29T14:49:47.401331562Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.00001",
   "id": "1cac82de22c93e0f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理",
   "id": "1f009cb73f3b359b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.474515780Z",
     "start_time": "2025-12-29T14:49:47.423451462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = forward(feature, weight, bias)\n",
    "\n",
    "print(f'prediction: {prediction}')"
   ],
   "id": "80233f0e967e1603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [43.05]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 评估",
   "id": "1e93b833d4a219ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.549227936Z",
     "start_time": "2025-12-29T14:49:47.480668433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "error = mse_loss(prediction, label)\n",
    "\n",
    "print(f'error: {error}')"
   ],
   "id": "608008ce09c030aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 14871.802500000002\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练",
   "id": "ece16e12446f6a95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 反向传播",
   "id": "9bf4b2cb78a2301"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.585014440Z",
     "start_time": "2025-12-29T14:49:47.556279058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "delta = gradient(prediction, label)\n",
    "weight, bias = backward(feature, delta, weight, bias, LEARNING_RATE)\n",
    "\n",
    "print(f\"weight: {weight}\")\n",
    "print(f\"bias: {bias}\")"
   ],
   "id": "1afc07eb317ef3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[0.5685359 0.641462 ]]\n",
      "bias: [0.002439]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "可以看出，通过引入合适的学习率，经过一次模型训练，权重和偏差的调整幅度变得相对合理。实际结果如何呢？",
   "id": "2c6c4b0c721865b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 重新评估",
   "id": "3b8b6a2d5b84392a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:49:47.752077373Z",
     "start_time": "2025-12-29T14:49:47.643011348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = forward(feature, weight, bias)\n",
    "error = mse_loss(prediction, label)\n",
    "\n",
    "print(f'error: {error}')"
   ],
   "id": "cd20ce9cb9a2e8db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 12503.020514375934\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "经过重新推理和评估，可以看出我们引入的学习率，经过一次模型训练，使损失值下降了大约20%。这已经在一个正常、合理的范围了。",
   "id": "2ce0d17887f6c69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# 梯度下降\n",
    "\n",
    "到目前为止，我们已经构建了一个最简单的人工神经元网络模型的完整框架：\n",
    "\n",
    "* **模型参数**：权重 $w$ 和偏置 $b$；\n",
    "* **模型逻辑**：前向传播与损失计算。\n",
    "\n",
    "其中，推理逻辑是固定的，而**模型的准确性完全取决于参数是否合理**。\n",
    "\n",
    "那么，如何获得合理的参数？答案是：让模型从数据中**自动学习**。这个过程称为**模型训练**（Model Training）。\n",
    "\n",
    "## 模型训练\n",
    "\n",
    "模型训练的目标很明确：**让损失函数的输出（损失值）尽可能小**。\n",
    "\n",
    "人工神经元的本质是线性回归。我们可以对损失函数进行**梯度下降**（Gradient Descent），来寻找更优的参数。\n",
    "\n",
    "---\n",
    "\n",
    "把推理函数代入损失函数，就会发现损失函数实际上是关于模型参数的函数。可以表示为 $L(w, b)$。\n",
    "\n",
    "**梯度**就是损失函数在某一点增加最快的方向，实质就是损失函数的导数。可以把梯度表示为：\n",
    "\n",
    "$$\n",
    "\\nabla L = \\left( \\frac{\\partial L}{\\partial w}, \\frac{\\partial L}{\\partial b} \\right)\n",
    "$$\n",
    "\n",
    "**下降**就是让模型参数沿着梯度相反的方向变化，从而达到让损失值变小的目的：\n",
    "\n",
    "$$\n",
    "w_{\\text{new}} = w_{\\text{old}} - \\frac{\\partial L}{\\partial w}\n",
    "$$\n",
    "$$\n",
    "b_{\\text{new}} = b_{\\text{old}} - \\frac{\\partial L}{\\partial b}\n",
    "$$"
   ],
   "id": "858e685ef64b01ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:53.099097210Z",
     "start_time": "2026-01-12T23:52:53.076304637Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "98f522323c77cd1f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据",
   "id": "ed262c084ffeff2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 特征、标签",
   "id": "a986148645ffbe00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:53.244877956Z",
     "start_time": "2026-01-12T23:52:53.136177611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature = np.array([28.1, 58.0])\n",
    "label = np.array([165.0])"
   ],
   "id": "5dc9076f8838ff0f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型",
   "id": "e0f988794356586d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 参数：权重、偏置",
   "id": "b80c9aa0309b7bf1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:53.469928345Z",
     "start_time": "2026-01-12T23:52:53.326415926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight = np.ones([1, 2]) / 2\n",
    "bias = np.zeros(1)"
   ],
   "id": "37aee2fbe9625d76",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理函数",
   "id": "584cb717f5f19d2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:53.511720576Z",
     "start_time": "2026-01-12T23:52:53.473849180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward(x, w, b):\n",
    "    return x @ w.T + b"
   ],
   "id": "c9a5523d452aa003",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（均方误差）",
   "id": "e898e53991ecde17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:53.616104647Z",
     "start_time": "2026-01-12T23:52:53.555832568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mse_loss(p, y):\n",
    "    return np.mean(np.square(y - p))"
   ],
   "id": "20e825f7e40efb91",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 梯度函数\n",
    "\n",
    "损失值是关于预测值的函数（损失函数）；预测值是关于模型参数的函数（推理函数）。\n",
    "\n",
    "根据微积分的**链式规则**（Chain Rule），我们可以分别计算两个函数的导数，然后将其相乘，从而获得损失值关于模型参数的导数。\n",
    "\n",
    "---\n",
    "\n",
    "损失函数是：$L = (y - p)^2$，导数是：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial p} = -2(y - p)\n",
    "$$\n",
    "\n",
    "推理函数是：$p = wx + b$，权重和偏置的导数分别是：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial p}{\\partial w} = x\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial p}{\\partial b} = 1\n",
    "$$\n",
    "\n",
    "因此，根据链式规则，权重和偏置的梯度分别是：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial p} \\cdot \\frac{\\partial p}{\\partial w} = -2(y - p) x\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial p} \\cdot \\frac{\\partial p}{\\partial b} = -2(y - p)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "梯度函数将计算权重梯度和偏置梯度的共同部分：$-2(y - p)$。在深度学习中，这个共同部分通常被称为**误差项**（Delta）。它是从损失函数反向传播的第一棒：\n",
    "\n",
    "$$\n",
    "\\delta = -2(y - p)\n",
    "$$"
   ],
   "id": "9cff97645d4a7fd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:53.645675387Z",
     "start_time": "2026-01-12T23:52:53.623100402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient(p, y):\n",
    "    return - 2 * (y - p)"
   ],
   "id": "ff83d27fd0b1633b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 反向函数\n",
    "\n",
    "反向函数将根据梯度调整权重和偏置。这种数据从输出反向向输入的流动，被称为**反向传播**（Backpropagation）：\n",
    "\n",
    "$$\n",
    "w = w - \\delta \\cdot x\n",
    "$$\n",
    "$$\n",
    "b = b - \\delta \\cdot 1\n",
    "$$"
   ],
   "id": "c12ee2534aa2c0f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:53.669098689Z",
     "start_time": "2026-01-12T23:52:53.648170236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward(x, d, w, b):\n",
    "    w = w - d * x\n",
    "    b = b - d\n",
    "    return w, b"
   ],
   "id": "15c244f1210c0188",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "fd69af83ac69912f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理",
   "id": "970311079abb6db3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:53.782868107Z",
     "start_time": "2026-01-12T23:52:53.681859317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = forward(feature, weight, bias)\n",
    "print(f'prediction: {prediction}')"
   ],
   "id": "11237f48834e66dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [43.05]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 评估",
   "id": "fb70fe9d5b31f624"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:54.039081319Z",
     "start_time": "2026-01-12T23:52:53.810220736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = mse_loss(prediction, label)\n",
    "print(f'loss: {loss}')"
   ],
   "id": "7c057d4ef0367bd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 14871.802500000002\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 训练\n",
    "\n",
    "现在，我们根据梯度下降的理论来进行第一次的模型训练。"
   ],
   "id": "15370c3b8e446497"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 梯度计算",
   "id": "2d543fbe9eefa2d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:54.158903566Z",
     "start_time": "2026-01-12T23:52:54.064594691Z"
    }
   },
   "cell_type": "code",
   "source": "delta = gradient(prediction, label)",
   "id": "8d045d95e9dc24a7",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 反向传播",
   "id": "6acca0570f0b4714"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:54.274910197Z",
     "start_time": "2026-01-12T23:52:54.178704616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight, bias = backward(feature, delta, weight, bias)\n",
    "print(f\"weight: {weight}\")\n",
    "print(f\"bias: {bias}\")"
   ],
   "id": "5043693c2ea19d4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[ 6854.09 14146.7 ]]\n",
      "bias: [243.9]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "经过一次模型训练，权重和偏置都有了明显的变化。效果如何呢？",
   "id": "482c49c4f109651e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 重新评估",
   "id": "fc22697d6edc3db8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T23:52:54.362236220Z",
     "start_time": "2026-01-12T23:52:54.278829846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = forward(feature, weight, bias)\n",
    "loss = mse_loss(prediction, label)\n",
    "print(f'loss: {loss}')"
   ],
   "id": "b44ff15e18970cb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1026548766283.6302\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "不幸的是，损失值严重恶化。这又是问什么呢？",
   "id": "31268071a2e85913"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# 隐藏层\n",
    "\n",
    "我们已经成功地训练了一个线性回归的机器学习模型，用来根据天气预报（温度、湿度）预测冰激凌销量。\n",
    "\n",
    "但是冰激凌的销量是直接和天气情况相关联吗？实际上，天气情况决定了人们出门的愿望，和购买冰激凌的欲望。而人们出门的愿望，和购买冰激凌的欲望才直接决定了冰激凌的销量。\n",
    "\n",
    "比如天气凉爽的时候，人们愿意出门，却未必愿意购买冰激凌；而天气酷热的时候，人们不愿意出门，但是有购买冰激凌的强烈愿望；等到天气寒冷的时候，人们即不愿意出门，也不想购买冰激凌。\n",
    "\n",
    "所以，理论上我们需要三个模型：第一个模型根据天气情况预测人们出门的愿望，第二个模型根据天气情况预测人们购买冰激凌的欲望；而第三个模型根据前两个模型的预测结果来预测冰激凌的销量。\n",
    "\n",
    "训练这样的三个模型，我们需要收集四组数据：\n",
    "* 天气预报\n",
    "* 顾客出门比例\n",
    "* 冰激凌购买比例\n",
    "* 冰激凌销量\n",
    "\n",
    "这里面的顾客出门比例，和冰激凌购买比例被称为中间数据。它们并不是我们直接需要的数据，也很难收集。\n",
    "\n",
    "## 层\n",
    "\n",
    "我们设想一下，是否可以把我们的模型分成两**层**（Layer）：\n",
    "\n",
    "* 第一层：根据天气情况预测两个数据：人们出门的愿望，和购买冰激凌的欲望。\n",
    "* 第二层：利用第一层的两个预测结果来预测冰激凌的销量。\n",
    "\n",
    "这样的模型是否更加合理？是否可行？\n"
   ],
   "id": "439914507894bde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.473776679Z",
     "start_time": "2026-01-01T00:14:42.401915511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(99)"
   ],
   "id": "3d34cc9e70b35618",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据集",
   "id": "ba8ff56c99608a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 训练数据：特征、标签",
   "id": "b0511e566fd559b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.556214630Z",
     "start_time": "2026-01-01T00:14:42.507840753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_features = np.array([[22.5, 72.0],\n",
    "                           [31.4, 45.0],\n",
    "                           [19.8, 85.0],\n",
    "                           [27.6, 63]])\n",
    "\n",
    "train_labels = np.array([[95],\n",
    "                        [210],\n",
    "                        [70],\n",
    "                        [155]])"
   ],
   "id": "5be3e528d59fe684",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 测试数据：特征、标签",
   "id": "dfb1087e1fe65e94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.633193210Z",
     "start_time": "2026-01-01T00:14:42.593623029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_features = np.array([[28.1, 58.0]])\n",
    "test_labels = np.array([[165]])"
   ],
   "id": "4b902606871d6284",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 模型\n",
    "\n",
    "两层的人工神经元网络模型，其数据流将变成传播链路：\n",
    "\n",
    "* 前向传播链路\n",
    "\n",
    "```{figure} layer-forward.png\n",
    ":align: center\n",
    ":width: 480px\n",
    "```\n",
    "\n",
    "* 梯度计算链路\n",
    "\n",
    "```{figure} layer-gradient.png\n",
    ":align: center\n",
    ":width: 680px\n",
    "```\n",
    "\n",
    "* 反向传播链路\n",
    "\n",
    "```{figure} layer-backward.png\n",
    ":align: center\n",
    ":width: 260px\n",
    "```\n",
    "\n",
    "两层模型训练的过程是多轮迭代，通过两层梯度，逐步调整两层参数，收敛到最优解。\n",
    "\n",
    "根据微积分的导数链式法则，两层模型的反向传播链是可行的。而且这个过程不需要中间值的参与，因此我们可以忽略中间值的实际含义。"
   ],
   "id": "be3893006b6db34d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 参数：隐藏层权重、偏差\n",
    "\n",
    "实际上，我们并没有办法要求模型在第一层必须预测人们出门的愿望，和购买冰激凌的欲望。除非我们可以提供有关人们出门的愿望，和购买冰激凌的欲望的实际数据给模型学习。\n",
    "\n",
    "我们只是要求模型在第一层先推理出若干中间值。这些中间值没有明确的实际含义，但是将成为第二层的更大数量、更高质量的训练数据。\n",
    "\n",
    "因此第一层通常称为**隐藏层**（Hidden Layer）。我们设置隐藏层推理出四个中间值。\n",
    "\n",
    "我们使用NumPy的随机数生成器，初始化四组随机数权重和偏差。这样的设置将引导模型沿着不同方向推理中间值。"
   ],
   "id": "1d7cd50aa8deb4e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.655829328Z",
     "start_time": "2026-01-01T00:14:42.634986985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_weight = np.random.rand(4, 2) / 2\n",
    "hidden_bias = np.random.rand(4)"
   ],
   "id": "455db01165f986a1",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 参数：输出层权重、偏差\n",
    "\n",
    "第二层通常称为**输出层**（Output Layer）。我们同样使用NumPy的随机数生成器来初始化权重和偏差。\n",
    "\n",
    "输出层将有四个输入数据，并推理出一个输出数据。"
   ],
   "id": "cbbc776923916f0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.683659522Z",
     "start_time": "2026-01-01T00:14:42.656853871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_weight = np.random.rand(1, 4) / 4\n",
    "output_bias = np.random.rand(1)"
   ],
   "id": "127624beb2186a2c",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理函数",
   "id": "c5186367e8f2c904"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.731081738Z",
     "start_time": "2026-01-01T00:14:42.697542382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward(x, w, b):\n",
    "    return x @ w.T + b"
   ],
   "id": "6496030f3a4467c3",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（平均平方差）",
   "id": "d16bc0f5bbd8e9a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.761208855Z",
     "start_time": "2026-01-01T00:14:42.736454800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mse_loss(p, y):\n",
    "    return np.mean(np.square(y - p))"
   ],
   "id": "e34d75d347417527",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 梯度函数",
   "id": "d846410965cebf7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.791224366Z",
     "start_time": "2026-01-01T00:14:42.763193211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient(p, y):\n",
    "    return - 2 * (y - p) / len(y)"
   ],
   "id": "8675f721162a4e63",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 反向函数\n",
    "\n",
    "隐藏层将产生四个中间值。我们需要调整一下反向函数关于偏差的计算：不再简单计算总和，而是按照批次的维度求和。这样可以保证每个中间值拥有不同的偏差。"
   ],
   "id": "534b6737fe72ed60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.849443963Z",
     "start_time": "2026-01-01T00:14:42.814546008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward(x, d, w, b, lr):\n",
    "    w = w - d.T @ x * lr\n",
    "    b = b - np.sum(d, axis=0) * lr\n",
    "    return w, b"
   ],
   "id": "d54bb231552f074d",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 梯度反向函数\n",
    "\n",
    "梯度反向函数用于从输出层梯度推导出隐藏层梯度。其本质就是输出层推理函数的偏导数。"
   ],
   "id": "8d6adfc2ffe14158"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.878349595Z",
     "start_time": "2026-01-01T00:14:42.859611636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_backward(d, w):\n",
    "    return d @ w"
   ],
   "id": "a35ca7e17ec3a232",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练",
   "id": "d6923a0cd52557e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 超参数：学习率",
   "id": "ec6a8829256ebe18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.939005425Z",
     "start_time": "2026-01-01T00:14:42.887317526Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.00001",
   "id": "ac03de93d18fe5e1",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 超参数：批大小",
   "id": "5f5c360df49cae6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.964248367Z",
     "start_time": "2026-01-01T00:14:42.941102174Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 2",
   "id": "382303d27b43d86e",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 超参数：轮数",
   "id": "b0dfd3eca48b9205"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:42.980190659Z",
     "start_time": "2026-01-01T00:14:42.966880683Z"
    }
   },
   "cell_type": "code",
   "source": "EPOCHS = 1000",
   "id": "cb483142e5574f19",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 迭代\n",
    "\n",
    "单层网络模型的反向传播链包括损失函数的偏导，和推理函数的偏导两部分。两层网络模型的反向传播链包括三部分：损失函数的偏导，输出层推理函数的偏导，和隐藏层推理函数的偏导。"
   ],
   "id": "550f5c518429503c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:43.147393414Z",
     "start_time": "2026-01-01T00:14:42.983008960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for i in range(0, len(train_features), BATCH_SIZE):\n",
    "        # 读入一个批次需要的多个训练数据：特征、标签\n",
    "        features = train_features[i: i + BATCH_SIZE]\n",
    "        labels = train_labels[i: i + BATCH_SIZE]\n",
    "\n",
    "        # 推理中间数据\n",
    "        hidden = forward(features, hidden_weight, hidden_bias)\n",
    "        # 推理输出数据\n",
    "        predictions = forward(hidden, output_weight, output_bias)\n",
    "        # 计算输出层梯度\n",
    "        output_delta = gradient(predictions, labels)\n",
    "        # 计算隐藏层梯度\n",
    "        hidden_delta = gradient_backward(output_delta, output_weight)\n",
    "        # 用输出层梯度更新输出层参数\n",
    "        output_weight, output_bias = backward(hidden, output_delta, output_weight, output_bias, LEARNING_RATE)\n",
    "        # 用隐藏层梯度更新隐藏层参数\n",
    "        hidden_weight, hidden_bias = backward(features, hidden_delta, hidden_weight, hidden_bias, LEARNING_RATE)\n",
    "\n",
    "print(f\"hidden weight: {hidden_weight}\")\n",
    "print(f\"hidden bias: {hidden_bias}\")\n",
    "print(f\"output weight: {output_weight}\")\n",
    "print(f\"output bias: {output_bias}\")"
   ],
   "id": "425bac625222a603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden weight: [[ 1.45353425 -0.14661746]\n",
      " [ 1.38767435 -0.33933946]\n",
      " [ 2.0254864  -0.21125674]\n",
      " [ 0.69613316 -0.14191958]]\n",
      "hidden bias: [1.00869983 0.0221608  0.79667756 0.75576452]\n",
      "output weight: [[1.35796276 1.30704936 1.91057461 0.67564236]]\n",
      "output bias: [1.00777367]\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "bb2a6eb94570a07d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理",
   "id": "7490761073719fb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:43.250469422Z",
     "start_time": "2026-01-01T00:14:43.150658282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden = forward(test_features, hidden_weight, hidden_bias)\n",
    "predictions = forward(hidden, output_weight, output_bias)\n",
    "\n",
    "print(f'predictions: {predictions}')"
   ],
   "id": "230e3a5364b0177a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [[166.58568956]]\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 评估",
   "id": "3f3c7aba00fb2e86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T00:14:43.320407351Z",
     "start_time": "2026-01-01T00:14:43.257448026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "error = mse_loss(predictions, test_labels)\n",
    "\n",
    "print(f'loss: {error}')"
   ],
   "id": "358201637e251f81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.5144113737205855\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "实践证明，两层网络模型是可行的，但是也没有比单层网络模型表现更好，甚至略有损耗。",
   "id": "d9a369fa6612b30e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

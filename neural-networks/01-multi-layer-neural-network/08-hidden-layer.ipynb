{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# 隐藏层\n",
    "\n",
    "到目前为止，我们成功地训练了一个线性回归的机器学习模型，用来根据天气预报（温度、湿度）预测冰激凌销量。\n",
    "\n",
    "-----------------\n",
    "\n",
    "回顾我们的模型，是根据天气预报预测冰激凌销量。但是冰激凌的销量是直接和天气情况相关联吗？实际上，天气情况决定了人们出门的愿望，和购买冰激凌的欲望。而人们出门的愿望，和购买冰激凌的欲望才直接决定了冰激凌的销量。\n",
    "\n",
    "比如天气凉爽的时候，人们愿意出门，却未必愿意购买冰激凌；而天气酷热的时候，人们不愿意出门，但是有购买冰激凌的强烈愿望；等到天气寒冷的时候，人们即不愿意出门，也不想购买冰激凌。\n",
    "\n",
    "-----------------\n",
    "\n",
    "所以，理论上我们需要三个模型：第一个模型根据天气情况预测人们出门的愿望，第二个模型根据天气情况预测人们购买冰激凌的欲望；而第三个模型根据前两个模型的预测结果来预测冰激凌的销量。\n",
    "\n",
    "训练这样的三个模型，我们需要收集四组数据：\n",
    "* 天气预报\n",
    "* 顾客出门比例\n",
    "* 冰激凌购买比例\n",
    "* 冰激凌销量\n",
    "\n",
    "这里面的顾客出门比例，和冰激凌购买比例被称为中间数据。它们并不是我们直接需要的数据，也很难收集。\n",
    "\n",
    "## 层\n",
    "\n",
    "我们设想一下，是否可以把我们的模型分成两**层**（Layer）：\n",
    "\n",
    "* 第一层：根据天气情况预测人们出门的愿望和购买冰激凌的欲望。\n",
    "* 第二层：利用第一层的预测结果来预测冰激凌的销量。\n",
    "\n",
    "这样的模型是否更加合理？是否可行？\n"
   ],
   "id": "439914507894bde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:27.551007387Z",
     "start_time": "2025-12-29T00:14:27.516554879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(99)"
   ],
   "id": "3d34cc9e70b35618",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据集",
   "id": "ba8ff56c99608a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 训练数据：特征、标签",
   "id": "b0511e566fd559b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:27.667949296Z",
     "start_time": "2025-12-29T00:14:27.553762164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_features = np.array([[22.5, 72.0],\n",
    "                           [31.4, 45.0],\n",
    "                           [19.8, 85.0],\n",
    "                           [27.6, 63]])\n",
    "\n",
    "train_labels = np.array([[95],\n",
    "                        [210],\n",
    "                        [70],\n",
    "                        [155]])"
   ],
   "id": "5be3e528d59fe684",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 验证数据：特征、标签",
   "id": "dfb1087e1fe65e94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:27.837200214Z",
     "start_time": "2025-12-29T00:14:27.724671890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_features = np.array([[28.1, 58.0]])\n",
    "test_labels = np.array([[165]])"
   ],
   "id": "4b902606871d6284",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 模型\n",
    "\n",
    "我们目前的单层模型的数据流是这样的：\n",
    "\n",
    "* 前向传播：输入数据 》》》参数 》》》输出数据\n",
    "* 反向传播：损失 》》》梯度 》》》参数\n",
    "\n",
    "模型训练的过程就是通过多轮次迭代，逐步调整参数收敛到最优解。\n",
    "\n",
    "我们将开始建立一个两层的人工神经元网络模型，数据流将是：\n",
    "\n",
    "* 前向传播：输入数据 》》》第一层参数 》》》中间数据 》》》第二层参数 》》》输出数据\n",
    "* 反向传播：损失 》》》第二层梯度 》》》第二层参数 》》》第一层梯度 》》》第一层参数\n",
    "\n",
    "两层模型训练的过程类似，也是通过多轮次迭代，通过两层梯度，逐步调整两层参数收敛到最优解。"
   ],
   "id": "be3893006b6db34d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 参数：隐藏层权重、偏差\n",
    "\n",
    "第一层通常称为**隐藏层**（Hidden Layer）。我们设置隐藏层推理出四个中间数据。\n",
    "\n",
    "我们使用NumPy的随机数生成器，初始化四组随机数权重和偏差。这样的设置将引导模型沿着不同方向推理中间数据。"
   ],
   "id": "1d7cd50aa8deb4e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:27.947015036Z",
     "start_time": "2025-12-29T00:14:27.872833974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_weight = np.random.rand(4, 2) / 2\n",
    "hidden_bias = np.random.rand(4)"
   ],
   "id": "455db01165f986a1",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 参数：输出层权重、偏差\n",
    "\n",
    "第二层通常称为**输出层**（Output Layer）。我们同样使用NumPy的随机数生成器来初始化权重和偏差。"
   ],
   "id": "cbbc776923916f0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:27.984184096Z",
     "start_time": "2025-12-29T00:14:27.956397343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_weight = np.random.rand(1, 4) / 4\n",
    "output_bias = np.zeros(1)"
   ],
   "id": "127624beb2186a2c",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理函数（前向传播）",
   "id": "c5186367e8f2c904"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.009886410Z",
     "start_time": "2025-12-29T00:14:27.988905445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward(x, w, b):\n",
    "    return x @ w.T + b"
   ],
   "id": "6496030f3a4467c3",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（平均平方差）",
   "id": "d16bc0f5bbd8e9a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.042111562Z",
     "start_time": "2025-12-29T00:14:28.015520712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mse_loss(p, y):\n",
    "    return ((p - y) ** 2).mean()"
   ],
   "id": "e34d75d347417527",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 梯度函数",
   "id": "d846410965cebf7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.070789502Z",
     "start_time": "2025-12-29T00:14:28.046621824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient(p, y):\n",
    "    return 2 * (p - y) / len(y)"
   ],
   "id": "8675f721162a4e63",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 超参数：学习率",
   "id": "9f5068dafa1e44a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.098811180Z",
     "start_time": "2025-12-29T00:14:28.075112977Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.00001",
   "id": "17fbba63ef41c448",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 反向函数（反向传播）",
   "id": "534b6737fe72ed60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.116797876Z",
     "start_time": "2025-12-29T00:14:28.102333164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward(x, d, w, b):\n",
    "    w -= d.T @ x * LEARNING_RATE\n",
    "    b -= np.sum(d, axis=0) * LEARNING_RATE\n",
    "    return w, b"
   ],
   "id": "d54bb231552f074d",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 梯度反向函数\n",
    "\n",
    "梯度方向函数用于通过输出层梯度推导出隐藏层梯度。其本质就是（输出层）推理函数的偏导数。"
   ],
   "id": "8d6adfc2ffe14158"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.129081264Z",
     "start_time": "2025-12-29T00:14:28.119448203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_backward(d, w):\n",
    "    return d @ w"
   ],
   "id": "a35ca7e17ec3a232",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练",
   "id": "d6923a0cd52557e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 超参数：批大小",
   "id": "5f5c360df49cae6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.153884466Z",
     "start_time": "2025-12-29T00:14:28.134350610Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 2",
   "id": "382303d27b43d86e",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 超参数：轮数",
   "id": "b0dfd3eca48b9205"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.172145281Z",
     "start_time": "2025-12-29T00:14:28.155562647Z"
    }
   },
   "cell_type": "code",
   "source": "EPOCHS = 1000",
   "id": "cb483142e5574f19",
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 迭代\n",
    "\n",
    "单层网络模型的反向传播链条包括损失函数的偏导，和推理函数的偏导两部分。两层网络模型的反向传播链条减肥包括三部分：损失函数的偏导，输出层推理函数的偏导，和隐藏层推理函数的偏导。"
   ],
   "id": "550f5c518429503c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.346132805Z",
     "start_time": "2025-12-29T00:14:28.174968688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for i in range(0, len(train_features), BATCH_SIZE):\n",
    "        # 读入一个批次需要的多个训练数据：特征、标签\n",
    "        features = train_features[i: i + BATCH_SIZE]\n",
    "        labels = train_labels[i: i + BATCH_SIZE]\n",
    "\n",
    "        # 推理中间数据\n",
    "        hidden = forward(features, hidden_weight, hidden_bias)\n",
    "        # 推理输出数据\n",
    "        predictions = forward(hidden, output_weight, output_bias)\n",
    "        # 计算输出层梯度\n",
    "        output_delta = gradient(predictions, labels)\n",
    "        # 计算隐藏层梯度\n",
    "        hidden_delta = gradient_backward(output_delta, output_weight)\n",
    "        # 用输出层梯度更新输出层参数\n",
    "        output_weight, output_bias = backward(hidden, output_delta, output_weight, output_bias)\n",
    "        # 用隐藏层梯度更新隐藏层参数\n",
    "        hidden_weight, hidden_bias = backward(features, hidden_delta, hidden_weight, hidden_bias)\n",
    "\n",
    "print(f\"hidden weight: {hidden_weight}\")\n",
    "print(f\"hidden bias: {hidden_bias}\")\n",
    "print(f\"output weight: {output_weight}\")\n",
    "print(f\"output bias: {output_bias}\")"
   ],
   "id": "425bac625222a603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden weight: [[ 1.45589229 -0.14549767]\n",
      " [ 1.38807669 -0.33787203]\n",
      " [ 2.02862972 -0.20931983]\n",
      " [ 0.69666255 -0.14108988]]\n",
      "hidden bias: [1.00877268 0.02219844 0.7967796  0.75579067]\n",
      "output weight: [[1.36052528 1.30734017 1.91386671 0.67613159]]\n",
      "output bias: [0.03387615]\n"
     ]
    }
   ],
   "execution_count": 174
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "bb2a6eb94570a07d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理",
   "id": "7490761073719fb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.406470634Z",
     "start_time": "2025-12-29T00:14:28.347732859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden = forward(test_features, hidden_weight, hidden_bias)\n",
    "predictions = forward(hidden, output_weight, output_bias)\n",
    "\n",
    "print(f'predictions: {predictions}')"
   ],
   "id": "230e3a5364b0177a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [[166.59001445]]\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 评估",
   "id": "3f3c7aba00fb2e86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T00:14:28.503392028Z",
     "start_time": "2025-12-29T00:14:28.410386249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "error = mse_loss(predictions, test_labels)\n",
    "\n",
    "print(f'error: {error}')"
   ],
   "id": "358201637e251f81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 2.528145949019884\n"
     ]
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "实践证明，两层网络模型是可行的，但是也没有比单层网络模型表现更好，甚至略有损耗。",
   "id": "d9a369fa6612b30e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# 优化器类\n",
    "\n",
    "我们通过张量封装了梯度计算链路，通过层封装了前向传播链路。\n",
    "\n",
    "现在，我们将引入**优化器**（Optimizer）类来封装反向传播链路，根据梯度更新参数。\n",
    "\n",
    "-----------------\n",
    "\n",
    "至此，我们完成了对神经网络模型三条数据链路的封装：\n",
    "* **张量**：梯度计算链路，组成计算图；\n",
    "* **层**：前向传播链路；\n",
    "* **损失函数**：前向传播链路和梯度计算链路的连接点；\n",
    "* **优化器**：反向传播链路。"
   ],
   "id": "c0dcf040878af3b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:11.918627214Z",
     "start_time": "2026-01-19T12:12:11.892184579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from abc import abstractmethod, ABC\n",
    "import numpy as np"
   ],
   "id": "f2f5f22af2a86f3e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 基础架构",
   "id": "d252316795f4aed2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 张量",
   "id": "3dcda0116d9179b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.036729600Z",
     "start_time": "2026-01-19T12:12:11.921088481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.grad = np.zeros_like(self.data)\n",
    "        self.gradient_fn = lambda: None\n",
    "        self.parents = set()\n",
    "\n",
    "    def backward(self):\n",
    "        if self.gradient_fn:\n",
    "            self.gradient_fn()\n",
    "\n",
    "        for p in self.parents:\n",
    "            p.backward()\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Tensor({self.data})'"
   ],
   "id": "c73ebea589dd19d8",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 基础层\n",
    "\n",
    "为了辅助实现反向传播链路的自动化，我们需要在层中添加一个新的属性：**参数列表**（parameters），用来返回本层需要参与反向传播的张量（通常是本层的模型参数）。"
   ],
   "id": "3e4acfae657d6646"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.156214238Z",
     "start_time": "2026-01-19T12:12:12.070993526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(ABC):\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: Tensor):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return ''"
   ],
   "id": "da65a5787200d264",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础损失函数",
   "id": "84802851c1fc1134"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.370059994Z",
     "start_time": "2026-01-19T12:12:12.177568040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss(ABC):\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        return self.loss(p, y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        pass"
   ],
   "id": "69b74596c9d28e1",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 基础优化器\n",
    "\n",
    "**基础优化器**（Base Optimizer）是一个抽象类，定义了一个**参数更新函数**（step）的虚拟接口，用来根据参数列表中所有张量的梯度，更新它们的数值。\n",
    "\n",
    "创建一个优化器，我们需要知道：\n",
    "\n",
    "* **参数列表**（parameters）：各层参与反向传播的张量列表，这些张量都需要根据梯度进行更新；\n",
    "* **学习率**（lr）：梯度更新比例系数。"
   ],
   "id": "93d5952827155637"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.439537693Z",
     "start_time": "2026-01-19T12:12:12.388849374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Optimizer(ABC):\n",
    "\n",
    "    def __init__(self, parameters, lr):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self):\n",
    "        pass"
   ],
   "id": "3c6e1f4d920bf6e0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据",
   "id": "230fe4f3eab660b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 特征、标签",
   "id": "14cec54c10fb3fd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.473078037Z",
     "start_time": "2026-01-19T12:12:12.444142628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature = Tensor([28.1, 58.0])\n",
    "label = Tensor([165])"
   ],
   "id": "b32de9bec9edab0c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型",
   "id": "bd311da042c1dac2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 线性层\n",
    "\n",
    "在线性层，我们把权重和偏置加入**参数列表**（parameters）。它们需要根据梯度进行更新。"
   ],
   "id": "9c6b7008038f13b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.499151742Z",
     "start_time": "2026-01-19T12:12:12.476430520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.weight = Tensor(np.ones((out_size, in_size)) / in_size)\n",
    "        self.bias = Tensor(np.zeros(out_size))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(x.data @ self.weight.data.T + self.bias.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.weight.grad += p.grad * x.data\n",
    "            self.bias.grad += np.sum(p.grad, axis=0)\n",
    "            x.grad += p.grad @ self.weight.data\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.weight, self.bias]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Linear[weight{self.weight.data.shape}; bias{self.bias.data.shape}]'"
   ],
   "id": "2eae8b64b6cd36cd",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（平均平方差）",
   "id": "98d53faf96bb990c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.520486682Z",
     "start_time": "2026-01-19T12:12:12.502382292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSELoss(Loss):\n",
    "\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        mse = Tensor(np.mean(np.square(y.data - p.data)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad += -2 * (y.data - p.data)\n",
    "\n",
    "        mse.gradient_fn = gradient_fn\n",
    "        mse.parents = {p}\n",
    "        return mse"
   ],
   "id": "cf0f9cc27095589c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 优化器（随机梯度下降）\n",
    "\n",
    "我们的第一个优化器类是**随机梯度下降优化器**（SGDOptimizer），按照固定的**学习率**（lr）更新**参数列表**（parameters）中的所有张量。"
   ],
   "id": "6ebebc9c9dfd7557"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.543436790Z",
     "start_time": "2026-01-19T12:12:12.524533416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SGDOptimizer(Optimizer):\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.parameters:\n",
    "            p.data -= p.grad * self.lr"
   ],
   "id": "57ac9997188205a4",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 设置",
   "id": "f905de96a0d45486"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 学习率",
   "id": "58531fb08ea838bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.569965592Z",
     "start_time": "2026-01-19T12:12:12.552153195Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.00001",
   "id": "add11273b4220ac0",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "7a8a858c46c80725"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 建模",
   "id": "b819cb7b1e2d3328"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.640135255Z",
     "start_time": "2026-01-19T12:12:12.575525926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer = Linear(feature.size, 1)\n",
    "print(layer)\n",
    "\n",
    "loss_fn = MSELoss()\n",
    "# 优化器\n",
    "optimizer = SGDOptimizer(layer.parameters, lr=LEARNING_RATE)"
   ],
   "id": "4ddb017a3fa27b5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear[weight(1, 2); bias(1,)]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理",
   "id": "245e3bf69f834167"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:12.878180304Z",
     "start_time": "2026-01-19T12:12:12.660953475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = layer(feature)\n",
    "print(f'prediction: {prediction}')"
   ],
   "id": "849d01453c043087",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: Tensor([43.05])\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 评估",
   "id": "12197a90e7728685"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:13.029083876Z",
     "start_time": "2026-01-19T12:12:12.936130720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = loss_fn(prediction, label)\n",
    "print(f'loss: {loss}')"
   ],
   "id": "89567b98057d0120",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: Tensor(14871.802500000002)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练",
   "id": "be5814a52b9c7507"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 梯度计算",
   "id": "38536fdb3f716bbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:13.056401939Z",
     "start_time": "2026-01-19T12:12:13.033237923Z"
    }
   },
   "cell_type": "code",
   "source": "loss.backward()",
   "id": "15a8f98d9b10b870",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 反向传播\n",
    "\n",
    "完成梯度计算以后，我们可以调用优化器的**更新参数函数**（step），完成一次迭代的反向传播。\n",
    "\n",
    "简单地讲，梯度计算完成以后，梯度值已经保存在各张量的**梯度**（grad）中。反向传播时，优化器只需要遍历**参数列表**（parameters），根据保存的梯度值，更新各张量的数值。"
   ],
   "id": "16a299a9855ae300"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:13.102825315Z",
     "start_time": "2026-01-19T12:12:13.065853926Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer.step()",
   "id": "218bd08752c1b980",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 重新评估",
   "id": "5e98246898bf3087"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:13.348461368Z",
     "start_time": "2026-01-19T12:12:13.124789623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = layer(feature)\n",
    "loss = loss_fn(prediction, label)\n",
    "print(f'loss: {loss}')"
   ],
   "id": "b9e95b1837c66cae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: Tensor(12503.020514375934)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "通过优化器类，我们实现了反向传播链路（更新参数）的自动化。",
   "id": "c120dad8cdbf2b5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 课后练习\n",
    "\n",
    "**父节点列表**（parents）和**参数列表**（parameters）的设计，使得计算图的遍历和反向传播都可以自动化完成。尝试把不同的张量从父节点列表和参数列表中移除，观察反向传播的结果如何？"
   ],
   "id": "ebe59abeaa279622"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

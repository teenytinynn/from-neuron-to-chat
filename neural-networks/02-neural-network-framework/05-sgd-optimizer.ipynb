{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# 优化器类\n",
    "\n",
    "我们通过张量封装了梯度计算，通过层封装了前向传播。\n",
    "\n",
    "现在，我们将引入优化器类（Optimizer）来封装反向传播（根据梯度更新参数）。\n",
    "\n",
    "-----------------\n",
    "\n",
    "至此，我们完成了对人工神经元网络模型三条数据链的封装：\n",
    "* 张量：梯度计算\n",
    "* 层：前向传播\n",
    "* 损失函数：前向传播和梯度计算的连接点\n",
    "* 优化器：反向传播"
   ],
   "id": "c0dcf040878af3b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:11.423194463Z",
     "start_time": "2026-01-08T03:24:11.410730794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from abc import abstractmethod, ABC\n",
    "import numpy as np"
   ],
   "id": "f2f5f22af2a86f3e",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 基础架构",
   "id": "d252316795f4aed2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 张量",
   "id": "3dcda0116d9179b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:11.487937597Z",
     "start_time": "2026-01-08T03:24:11.429382311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.grad = np.zeros_like(self.data)\n",
    "        self.gradient_fn = lambda: None\n",
    "        self.parents = set()\n",
    "\n",
    "    def backward(self):\n",
    "        if self.gradient_fn:\n",
    "            self.gradient_fn()\n",
    "\n",
    "        for p in self.parents:\n",
    "            p.backward()\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Tensor({self.data})'"
   ],
   "id": "c73ebea589dd19d8",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 基础层\n",
    "\n",
    "为了配合优化器自动化反向传播的目的，我们需要在层中添加一个parameters()函数，来返回本层需要参与反向传播的张量（各类参数和预测值）。"
   ],
   "id": "3e4acfae657d6646"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:11.688330124Z",
     "start_time": "2026-01-08T03:24:11.538155193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(ABC):\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: Tensor):\n",
    "        pass\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "    def __str__(self):\n",
    "        return ''"
   ],
   "id": "da65a5787200d264",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础损失函数",
   "id": "84802851c1fc1134"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:11.886798646Z",
     "start_time": "2026-01-08T03:24:11.735957947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss(ABC):\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        return self.loss(p, y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        pass"
   ],
   "id": "69b74596c9d28e1",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 基础优化器\n",
    "\n",
    "基础优化器是一个抽象类，定义了一个反向传播的接口。\n",
    "\n",
    "优化器需要两个参数：\n",
    "* parameters：各层参与反向传播的张量集合，这些张量都需要根据梯度进行更新\n",
    "* lr：学习率"
   ],
   "id": "93d5952827155637"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:11.960551377Z",
     "start_time": "2026-01-08T03:24:11.892218566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Optimizer(ABC):\n",
    "\n",
    "    def __init__(self, parameters, lr):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self):\n",
    "        pass"
   ],
   "id": "3c6e1f4d920bf6e0",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据",
   "id": "230fe4f3eab660b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 特征、标签",
   "id": "14cec54c10fb3fd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.034899214Z",
     "start_time": "2026-01-08T03:24:12.003192420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature = Tensor([28.1, 58.0])\n",
    "label = Tensor([165])"
   ],
   "id": "b32de9bec9edab0c",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型",
   "id": "bd311da042c1dac2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 线性层\n",
    "\n",
    "在线性层，权重和偏置需要参与反向传播，需要根据梯度进行更新。"
   ],
   "id": "9c6b7008038f13b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.152914691Z",
     "start_time": "2026-01-08T03:24:12.037552358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.weight = Tensor(np.ones((out_size, in_size)) / in_size)\n",
    "        self.bias = Tensor(np.zeros(out_size))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(x.data @ self.weight.data.T + self.bias.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.weight.grad += p.grad * x.data\n",
    "            self.bias.grad += np.sum(p.grad, axis=0)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        return p\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight, self.bias]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Linear[weight{self.weight.data.shape}; bias{self.bias.data.shape}]'"
   ],
   "id": "2eae8b64b6cd36cd",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 损失函数（平均平方差）",
   "id": "98d53faf96bb990c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.230298051Z",
     "start_time": "2026-01-08T03:24:12.194211489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSELoss(Loss):\n",
    "\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        mse = Tensor(np.mean(np.square(y.data - p.data)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad += -2 * (y.data - p.data)\n",
    "\n",
    "        mse.gradient_fn = gradient_fn\n",
    "        mse.parents = {p}\n",
    "        return mse"
   ],
   "id": "cf0f9cc27095589c",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 优化器（随机梯度下降）\n",
    "\n",
    "优化器（随机梯度下降）继承了基础优化器的接口，根据梯度随机下降的规则更新parameters中的所有张量。"
   ],
   "id": "6ebebc9c9dfd7557"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.255234302Z",
     "start_time": "2026-01-08T03:24:12.236289401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SGDOptimizer(Optimizer):\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.parameters:\n",
    "            p.data -= p.grad * self.lr"
   ],
   "id": "57ac9997188205a4",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 设置",
   "id": "f905de96a0d45486"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 学习率",
   "id": "58531fb08ea838bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.274669874Z",
     "start_time": "2026-01-08T03:24:12.258608714Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.00001",
   "id": "add11273b4220ac0",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "7a8a858c46c80725"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理",
   "id": "245e3bf69f834167"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.329718189Z",
     "start_time": "2026-01-08T03:24:12.278871519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer = Linear(feature.size(), 1)\n",
    "prediction = layer(feature)\n",
    "print(f'prediction: {prediction}')"
   ],
   "id": "849d01453c043087",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: Tensor([43.05])\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 评估",
   "id": "12197a90e7728685"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.392436663Z",
     "start_time": "2026-01-08T03:24:12.337059652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = MSELoss()\n",
    "error = loss(prediction, label)\n",
    "print(f'error: {error}')"
   ],
   "id": "89567b98057d0120",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Tensor(14871.802500000002)\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练",
   "id": "be5814a52b9c7507"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 梯度计算",
   "id": "38536fdb3f716bbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.419679839Z",
     "start_time": "2026-01-08T03:24:12.399208646Z"
    }
   },
   "cell_type": "code",
   "source": "error.backward()",
   "id": "15a8f98d9b10b870",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 反向传播\n",
    "\n",
    "完成梯度计算以后，我们可以方便地调用优化器的step()函数，完成一次迭代的反向传播。\n",
    "\n",
    "在创建优化器的时候，我们需要提供每层所有需要更新的张量的集合。"
   ],
   "id": "16a299a9855ae300"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.478434282Z",
     "start_time": "2026-01-08T03:24:12.427338625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = SGDOptimizer(layer.parameters(), lr=LEARNING_RATE)\n",
    "optimizer.step()\n",
    "print(layer)"
   ],
   "id": "218bd08752c1b980",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear[weight(1, 2); bias(1,)]\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 重新评估",
   "id": "5e98246898bf3087"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T03:24:12.565963712Z",
     "start_time": "2026-01-08T03:24:12.486397708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = layer(feature)\n",
    "error = loss(prediction, label)\n",
    "print(f'error: {error}')"
   ],
   "id": "b9e95b1837c66cae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Tensor(12503.020514375934)\n"
     ]
    }
   ],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# 损失函数类\n",
    "\n",
    "损失函数是前向传播链路的终点，也是梯度计算链路的起点。\n",
    "\n",
    "我们要把损失函数封装进**损失函数**（Loss）类。它将和张量类、层类一起，实现前向传播和梯度计算的逻辑闭环。这个闭环，称为**计算图**（Computational Graph）。\n",
    "\n",
    "## 计算图\n",
    "\n",
    "我们已经知道，神经网络模型并不是一次性地从输入数据计算出输出数据。而是输入数据经过一层一层的神经元，通过多次（简单）计算最终得出输出数据。这个数据流通的线路，被称为前向传播。\n",
    "\n",
    "在前向传播的过程中，我们需要记录下来输入数据流通的整个**拓扑结构**。因为我们需要通过这个拓扑结构反向地逐级计算梯度。这个数据前向传播的拓扑结构，称为**计算图**。\n",
    "\n",
    "计算图从特征值开始，沿着层结构，最终汇合到损失函数。计算图中的每个节点都由张量构成，可能是参数，可能是中间值；最后一个节点通常是损失值。\n",
    "\n",
    "因为它是在前向传播的过程中动态构建起来的，所以称为**动态计算图**（Dynamic Computational Graph）；相对应的，在前向传播进行前，就先构建好的计算图，称为**静态计算图**（Static Computational Graph）。PyTorch采用动态计算图技术，而TensorFlow则采用静态计算图技术。我们将采用动态计算图技术。"
   ],
   "id": "c0dcf040878af3b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.123696775Z",
     "start_time": "2026-01-19T12:12:00.086002036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from abc import abstractmethod, ABC\n",
    "import numpy as np"
   ],
   "id": "f2f5f22af2a86f3e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 基础架构",
   "id": "ae2eb41dc3220317"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 张量",
   "id": "3dcda0116d9179b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.182102008Z",
     "start_time": "2026-01-19T12:12:00.150840709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Tensor({self.data})'"
   ],
   "id": "c73ebea589dd19d8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 基础层",
   "id": "3e4acfae657d6646"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.210770815Z",
     "start_time": "2026-01-19T12:12:00.195598730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(ABC):\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: Tensor):\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return ''"
   ],
   "id": "da65a5787200d264",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 基础损失函数\n",
    "\n",
    "和基础层一样，**基础损失函数**（Base Loss）也是一个抽象类，定义了一个**计算损失**（loss）的虚拟接口。这个接口需要返回一个损失值的张量，作为梯度计算的起点。"
   ],
   "id": "84802851c1fc1134"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.246665397Z",
     "start_time": "2026-01-19T12:12:00.218321973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss(ABC):\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        return self.loss(p, y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        pass"
   ],
   "id": "69b74596c9d28e1",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据",
   "id": "c9984dd2af521652"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 特征、标签\n",
    "\n",
    "我们需要提供**标签值**，这样损失函数才能计算损失值。"
   ],
   "id": "844ec0a8477f878"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.277127558Z",
     "start_time": "2026-01-19T12:12:00.260933415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature = Tensor([28.1, 58.0])\n",
    "label = Tensor([165])"
   ],
   "id": "c36d86eff1bb8a80",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型",
   "id": "2acdb47821c754c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 线性层",
   "id": "f1c118e905b103f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.304260051Z",
     "start_time": "2026-01-19T12:12:00.280171230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.weight = Tensor(np.ones((out_size, in_size)) / in_size)\n",
    "        self.bias = Tensor(np.zeros(out_size))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return Tensor(x.data @ self.weight.data.T + self.bias.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Linear[weight{self.weight.data.shape}; bias{self.bias.data.shape}]'"
   ],
   "id": "f63a10538421705b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 损失函数（均方误差）\n",
    "\n",
    "我们定义的第一个损失函数类是**均方误差损失函数**（MSELoss）。它封装了计算均方误差的功能，这是数值回归模型最常用的损失函数。"
   ],
   "id": "4c73a7f93691f370"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.402232509Z",
     "start_time": "2026-01-19T12:12:00.305920433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSELoss(Loss):\n",
    "\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        return Tensor(np.mean(np.square(y.data - p.data)))"
   ],
   "id": "a0a203ff2812af61",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 验证",
   "id": "f394223ea03c1b17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 建模",
   "id": "3cbdf3114ce2747a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.476429665Z",
     "start_time": "2026-01-19T12:12:00.409619290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 层\n",
    "layer = Linear(feature.size, 1)\n",
    "print(layer)\n",
    "# 损失函数\n",
    "loss_fn = MSELoss()"
   ],
   "id": "87654af588f0e1ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear[weight(1, 2); bias(1,)]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 推理",
   "id": "245e3bf69f834167"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.573538687Z",
     "start_time": "2026-01-19T12:12:00.484718352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = layer(feature)\n",
    "print(f'prediction: {prediction}')"
   ],
   "id": "849d01453c043087",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: Tensor([43.05])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 评估",
   "id": "12197a90e7728685"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T12:12:00.658295709Z",
     "start_time": "2026-01-19T12:12:00.583542991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = loss_fn(prediction, label)\n",
    "print(f'loss: {loss}')"
   ],
   "id": "89567b98057d0120",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: Tensor(14871.802500000002)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "损失函数类实现了前向传播链路和梯度计算链路的闭环。下一步，我们将在此基础上，实现自动微分和动态计算图，完成最复杂的梯度计算的自动化。",
   "id": "87d0f2d44a8ab0bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 课后练习\n",
    "\n",
    "试试创建一个新的损失函数类：**平均绝对误差损失函数**（MAELoss）。它是数值回归模型中，另一种常用的损失函数。它的公式是：\n",
    "\n",
    "   $$\n",
    "   \\text{mean absolute error} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - p_i|\n",
    "   $$"
   ],
   "id": "ce5e83f76b2a3ccc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

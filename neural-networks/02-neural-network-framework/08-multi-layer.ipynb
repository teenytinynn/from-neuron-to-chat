{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# 复合层",
   "id": "c0dcf040878af3b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:11.428539631Z",
     "start_time": "2026-01-01T03:11:11.374326365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from abc import abstractmethod, ABC\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(99)"
   ],
   "id": "f2f5f22af2a86f3e",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Foundation",
   "id": "8787c41aaafa0fb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tensor",
   "id": "3dcda0116d9179b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:11.575199992Z",
     "start_time": "2026-01-01T03:11:11.431996688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.grad = 0\n",
    "        self.gradient_fn = lambda: None\n",
    "        self.parents = set()\n",
    "\n",
    "    def backward(self):\n",
    "        if self.gradient_fn:\n",
    "            self.gradient_fn()\n",
    "\n",
    "        for p in self.parents:\n",
    "            p.backward()\n",
    "\n",
    "    def size(self):\n",
    "        return self.data.shape[-1]\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.data)"
   ],
   "id": "c73ebea589dd19d8",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Dataset",
   "id": "e29266672fff094f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:11.630680955Z",
     "start_time": "2026-01-01T03:11:11.590678292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Dataset(ABC):\n",
    "\n",
    "    def __init__(self, batch_size=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.load()\n",
    "        self.train()\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        self.features = self.train_features\n",
    "        self.labels = self.train_labels\n",
    "\n",
    "    def eval(self):\n",
    "        self.features = self.test_features\n",
    "        self.labels = self.test_labels\n",
    "\n",
    "    def shape(self):\n",
    "        return Tensor(self.features).size(), Tensor(self.labels).size()\n",
    "\n",
    "    def items(self):\n",
    "        return Tensor(self.features), Tensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "\n",
    "        feature = Tensor(self.features[start: end])\n",
    "        label = Tensor(self.labels[start: end])\n",
    "        return feature, label\n",
    "\n",
    "    @abstractmethod\n",
    "    def estimate(self, predictions):\n",
    "        pass"
   ],
   "id": "fde9ac4c2e187db5",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Layer",
   "id": "3e4acfae657d6646"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:11.686790331Z",
     "start_time": "2026-01-01T03:11:11.650977147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(ABC):\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: Tensor):\n",
    "        pass\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "    def __str__(self):\n",
    "        return ''"
   ],
   "id": "da65a5787200d264",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Loss Function",
   "id": "84802851c1fc1134"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:11.813257331Z",
     "start_time": "2026-01-01T03:11:11.739021345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss(ABC):\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        return self.loss(p, y)\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        pass"
   ],
   "id": "69b74596c9d28e1",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Optimizer",
   "id": "93d5952827155637"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:11.865097962Z",
     "start_time": "2026-01-01T03:11:11.840323134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Optimizer(ABC):\n",
    "\n",
    "    def __init__(self, parameters, lr):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "\n",
    "    def clear(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad = 0\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self):\n",
    "        pass"
   ],
   "id": "3c6e1f4d920bf6e0",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base Model",
   "id": "e0f05df627ac3f48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:11.896458010Z",
     "start_time": "2026-01-01T03:11:11.872717170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(ABC):\n",
    "\n",
    "    def __init__(self, layer, loss, optimizer):\n",
    "        self.layer = layer\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, dataset, epochs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def test(self, dataset):\n",
    "        pass"
   ],
   "id": "7d86c6176d4f3ce9",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data",
   "id": "299a8affdbf8d41f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MLP Dataset",
   "id": "39bc2977c2b303e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.047647492Z",
     "start_time": "2026-01-01T03:11:11.901938903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLPDataset(Dataset):\n",
    "\n",
    "    def load(self):\n",
    "        self.train_features = [[22.5, 72.0],\n",
    "                               [31.4, 45.0],\n",
    "                               [19.8, 85.0],\n",
    "                               [27.6, 63]]\n",
    "\n",
    "        self.train_labels = [[95],\n",
    "                             [210],\n",
    "                             [70],\n",
    "                             [155]]\n",
    "\n",
    "        self.test_features = [[28.1, 58.0]]\n",
    "\n",
    "        self.test_labels = [[165]]\n",
    "\n",
    "    def estimate(self, predictions):\n",
    "        return ((predictions.data - self.labels) ** 2).mean()"
   ],
   "id": "8693fd5b3444aa4e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "9613c2e294d97651"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Layer",
   "id": "2030f3dbc60eb905"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.074669778Z",
     "start_time": "2026-01-01T03:11:12.055893013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.weight = Tensor(np.random.rand(out_size, in_size) / in_size)\n",
    "        self.bias = Tensor(np.random.rand(out_size))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(x.data @ self.weight.data.T + self.bias.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.weight.grad += p.grad.T @ x.data / len(x.data)\n",
    "            self.bias.grad += np.sum(p.grad, axis=0) / len(x.data)\n",
    "            x.grad += p.grad @ self.weight.data\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self.weight, self.bias, x}\n",
    "        return p\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight, self.bias]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'weight: {self.weight}\\nbias: {self.bias}'"
   ],
   "id": "10b000a8292151c1",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sequential Layer",
   "id": "7971f8f29b5480c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.098668134Z",
     "start_time": "2026-01-01T03:11:12.078276996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sequential(Layer):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join(str(l) for l in self.layers if str(l))"
   ],
   "id": "6c8fb46d4a1d4a45",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MSE Loss Function",
   "id": "23a67fb946fd2794"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.113175422Z",
     "start_time": "2026-01-01T03:11:12.099950316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MSELoss(Loss):\n",
    "\n",
    "    def loss(self, p: Tensor, y: Tensor):\n",
    "        mse = Tensor(np.mean(np.square(y.data - p.data)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad += -2 * (y.data - p.data)\n",
    "\n",
    "        mse.gradient_fn = gradient_fn\n",
    "        mse.parents = {p}\n",
    "        return mse"
   ],
   "id": "24be6f667d5c7675",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SGD Optimizer",
   "id": "7c8c4f46981e5d78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.133668564Z",
     "start_time": "2026-01-01T03:11:12.116857830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SGDOptimizer(Optimizer):\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.parameters:\n",
    "            p.data -= p.grad * self.lr"
   ],
   "id": "d4530b30eb5a9990",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Neural Network Model",
   "id": "8359292a154d7e03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.151330506Z",
     "start_time": "2026-01-01T03:11:12.136424233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NNModel(Model):\n",
    "\n",
    "    def train(self, dataset, epochs):\n",
    "        dataset.train()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(dataset)):\n",
    "                features, labels = dataset[i]\n",
    "\n",
    "                predictions = self.layer(features)\n",
    "                error = self.loss(predictions, labels)\n",
    "\n",
    "                self.optimizer.clear()\n",
    "                error.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "    def test(self, dataset):\n",
    "        dataset.eval()\n",
    "\n",
    "        features, labels = dataset.items()\n",
    "        return self.layer(features)\n"
   ],
   "id": "bba9b83d7db71240",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "e79dd248edf181b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Learning Rate",
   "id": "ead39b999187be57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.187835014Z",
     "start_time": "2026-01-01T03:11:12.160738176Z"
    }
   },
   "cell_type": "code",
   "source": "LEARNING_RATE = 0.00001",
   "id": "37e4421bb9b4a475",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Batch",
   "id": "8bf1986dcc63604b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.204114975Z",
     "start_time": "2026-01-01T03:11:12.191708052Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 2",
   "id": "2595e442ad7428b8",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Epoch",
   "id": "1a2c135127fda038"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.217958346Z",
     "start_time": "2026-01-01T03:11:12.206588791Z"
    }
   },
   "cell_type": "code",
   "source": "EPOCHS = 1000",
   "id": "f5770ada604b656",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "33b172a705285079"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Iterative Training",
   "id": "68cdc2886a10c6da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.568867124Z",
     "start_time": "2026-01-01T03:11:12.221486196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = MLPDataset(BATCH_SIZE)\n",
    "layer = Sequential([Linear(dataset.shape()[0], 4),\n",
    "                    Linear(4, dataset.shape()[1])])\n",
    "loss = MSELoss()\n",
    "optimizer = SGDOptimizer(layer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model = NNModel(layer, loss, optimizer)\n",
    "model.train(dataset, EPOCHS)\n",
    "\n",
    "print(layer)"
   ],
   "id": "514175203a080205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[ 1.45353425 -0.14661746]\n",
      " [ 1.38767435 -0.33933946]\n",
      " [ 2.0254864  -0.21125674]\n",
      " [ 0.69613316 -0.14191958]]\n",
      "bias: [1.00869983 0.0221608  0.79667756 0.75576452]\n",
      "weight: [[1.35796276 1.30704936 1.91057461 0.67564236]]\n",
      "bias: [1.00777367]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing",
   "id": "76d0eb3a42ab53e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Estimating",
   "id": "245e3bf69f834167"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T03:11:12.620898564Z",
     "start_time": "2026-01-01T03:11:12.570141973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = model.test(dataset)\n",
    "\n",
    "print(f'prediction: {predictions}')\n",
    "print(f'error: {dataset.estimate(predictions)}')"
   ],
   "id": "849d01453c043087",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [[166.58568956]]\n",
      "error: 2.5144113737205855\n"
     ]
    }
   ],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
